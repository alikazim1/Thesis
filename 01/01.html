<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
    <link rel="stylesheet" href="01.css" />
  </head>
  <body>
    <div class="navbar">
      <a href="index.html">Home</a>
      <a href="#about">About</a>
      <a href="#services">Services</a>
      <a href="#contact">Contact</a>
    </div>
    <button class="openbtn" onclick="toggleSidebar()">☰</button>
    <div class="sidebar" id="sidebar">
      <h2>Chapter Navigation</h2>
      <a href="#section1">Prerequisites</a>
      <a href="#section2">Introduction to AI</a>
      <a href="#section3">PyTorch</a>
      <a href="#section4">Where PyTorch is used?</a>
      <a href="#section5">Setting up Environment for PyTorch</a>
      <a href="#section6">Tensor</a>
      <a href="#section7">Methods in Tensor</a>
      <a href="#section8">Tensor Operations</a>
      <a href="#section9">Playing More</a>
      <a href="#section10">Interoperability with NumPy</a>
      <a href="#section11">Reproducibility</a>
      <a href="#section12">GPU Action</a>
      <a href="#section13">Exercise</a>
    </div>

    <div class="content">
      <h1>01. PyTorch Workflow Fundamentals</h1>

      <p>
        Training a deep learning neural network is similar to a professor
        training a student for an exam. Initially, the professor gathers the
        syllabus and splits it into a training part and a test part. The student
        is trained on the training material and is then subjected to the test.
        Based on the test results, the professor calculates the score and
        suggests that the student minimize their errors. Similarly, in deep
        learning, a model is trained on a dataset and then evaluated on a test
        set, with adjustments made to minimize the loss function.
      </p>
      <img
        src="neural_network_training_analogy.png"
        class="centered-image"
      />

      <p>
        The crux of machine and deep learning is to take data, build an
        algorithm(neural network) to discover deep patterns in it and use the
        discovered patterns to generate new data.
      </p>
      <img src="deepLearningpng.png" class="centered-image" />

      <p>
        There are many ways to design this process. We start from the very
        basic; which is predicting a straight line. We will see if we can build
        a PyTorch model that learns the patterns of straight line and matches
        it.
      </p>
      <br />
      <img src="2.png" class="centered-image" />

      <p>
        All of the materials for this course are available on
        <a href="" target="_blank">GitHub</a>
      </p>
      <p>
        If you got into any trouble, you can ask questions on the
        <a href="https://discuss.pytorch.org/" target="_blank"
          >Discussion page</a
        >
        there too.
      </p>
      <p>
        Now we are going to import torch, torch.nn ( nn stands for neural
        network and this package contains the building block for creating a
        neural networks in PyTorch) and matplotlib for plotting graphs
      </p>
      <div class="code-container">
        <button class="copy-button" onclick="copyCode(this)">Copy</button>
        <pre>
          <code>
          import torch
          from torch import nn # nn contains all of PyTorch's building blocks for neural networks
          import matplotlib.pyplot as plt
          
          # Check PyTorch version
          torch.__version__
        </code>
      <code>
        output: '1.12.1+cu113'
      </code></pre>
      </div>

      <h2>1. Data(Preparing and Loading)</h2>
      <p>
        Data can be anything that we can imagine. For instance an excel sheet,
        images of any kind, vidoes(youtube etc), audio files like songs or
        podcasts, blackhole dimensions, text and more.
      </p>
      <img src="./dataPreparation.png" class="centered-image" />
      <p>Machine learning has two main steps:</p>
      <li>Convert Data into numbers (a representation of data)</li>
      <li>Build or select a model to learn patterns in those numbers</li>
      <br>Sometimes, these steps happen together.</br>
      <br />What if there is no data?<br />
      <br>No problem! we can create our own.</br>
      <br>Let's start with a simple example:</br>
      <li>
        Create data as a straight line using linear regression with known
        parameters.
      </li>
      <li>
        Use PyTorch to build a model that estimates these parameters using
        gradient descent.
      </li>
      <br>
      <div class="code-container">
        <button class="copy-button" onclick="copyCode(this)">Copy</button>
        <pre>
          <code>
  # Create *known* parameters
  weight = 0.7
  bias = 0.3
  
  # Create data
  start = 0
  end = 1
  step = 0.02
  X = torch.arange(start, end, step).unsqueeze(dim=1)
  y = weight * X + bias
  
  X[:10], y[:10]
  
  output:
  (tensor([[0.0000],
           [0.0200],
           [0.0400],
           [0.0600],
           [0.0800],
           [0.1000],
           [0.1200],
           [0.1400],
           [0.1600],
           [0.1800]]),
   tensor([[0.3000],
           [0.3140],
           [0.3280],
           [0.3420],
           [0.3560],
           [0.3700],
           [0.3840],
           [0.3980],
           [0.4120],
           [0.4260]]))
          </code>
        </pre>
  
      </div>
    <p>
      Beautiful! Now, let’s build a model to learn the relationship between X (features) and y (labels).
    </p>
    <br>
    <h2>Split the data into training and test sets</h2>
    <p>
      We have our data, but before building a model, we need to split it.

Creating training, test, and (if needed) validation sets is a crucial step in any machine learning project.

Each split has a specific purpose:
    </p>
    <table>
      <thead>
          <tr>
              <th>Split</th>
              <th>Purpose</th>
              <th>Amount of total data</th>
              <th>How often is it used?</th>
          </tr>
      </thead>
      <tbody>
          <tr>
              <td>Training set</td>
              <td>The model learns from this data (like the course materials you study during the semester).</td>
              <td>~60-80%</td>
              <td>Always</td>
          </tr>
          <tr>
              <td>Validation set</td>
              <td>The model gets tuned on this data (like the practice exam you take before the final exam).</td>
              <td>~10-20%</td>
              <td>Often but not always</td>
          </tr>
          <tr>
              <td>Testing set</td>
              <td>The model gets evaluated on this data to test what it has learned (like the final exam you take at the end of the semester).</td>
              <td>~10-20%</td>
              <td>Always</td>
          </tr>
      </tbody>
  </table>
  <br>
  <p>
    For now, we’ll use just a training set and a test set:
  </p>
  <li>
    Training set: For the model to learn.
  </li>
  <li>
    Test set: For evaluating the model.
  </li>


  <div class="note">
    <strong>Note:</strong>In real-world projects, this step is done at the very beginning. The test set should always remain separate from the other data to avoid any bias. The goal is for the model to learn from the training data and then be evaluated on the test data to see how well it performs on unseen examples. This gives us an idea of how well the model generalizes.
</div>
<br>
<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
  # Create train/test split
  train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing 
  X_train, y_train = X[:train_split], y[:train_split]
  X_test, y_test = X[train_split:], y[train_split:]
  
  len(X_train), len(y_train), len(X_test), len(y_test)
  
  output: (40, 40, 10, 10)
    </code>
  </pre>
</div>
<br>
<p>
  Great! We have 40 samples for training (X_train & y_train) and 10 samples for testing (X_test & y_test).

Our model will learn the relationship between X_train and y_train, and we’ll evaluate its performance on X_test and y_test.

But right now, our data is just numbers on a page. Let's create a function to visualize it and get a better understanding of the data!
</p>
<br>  
<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
      def plot_predictions(train_data=X_train, 
                       train_labels=y_train, 
                       test_data=X_test, 
                       test_labels=y_test, 
                       predictions=None):
    """
    Plots training data, test data and compares predictions.
    """
    plt.figure(figsize=(10, 7))
  
    # Plot training data in blue
    plt.scatter(train_data, train_labels, c="b", s=4, label="Training data")
    
    # Plot test data in green
    plt.scatter(test_data, test_labels, c="g", s=4, label="Testing data")
  
    if predictions is not None:
      # Plot the predictions in red (predictions were made on the test data)
      plt.scatter(test_data, predictions, c="r", s=4, label="Predictions")
  
    # Show the legend
    plt.legend(prop={"size": 14});
  
    plot_predictions();
    </code>
  </pre>
</div>

<img src="plotPred.png"  class="centered-image">
<br>
<p>

Epic!

Now, instead of just numbers on a page, we can see that our data forms a straight line. This helps visualize the relationship between the features (X) and labels (y), making it easier to understand how our model will learn from the data.
</p>

<div class="note">
 <strong>Note: </strong> Here’s a great motto for any data explorer: "Visualize, visualize, visualize!"

Whenever you're working with data and converting it into numbers, keep this in mind. Visualization helps us understand the data in a much clearer way.

Machines are great with numbers, and while we humans like numbers too, we also love to see things visually. Visualizing data is a powerful tool for insight!
</div>
<br>


<h2>2. Build a model</h2>

<p>
  Now that we have data, let’s build a model that uses the blue dots (features) to predict the green dots (labels). We’ll dive right into the code, then explain each step. <br> <br>

Our goal is to replicate a standard linear regression model using pure PyTorch. Let's get started!
</p>

<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre><code>
    # Create a Linear Regression model class
    class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)
        def __init__(self):
            super().__init__() 
            self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)
                                                    dtype=torch.float), # <- PyTorch loves float32 by default
                                       requires_grad=True) # <- can we update this value with gradient descent?)
    
            self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)
                                                dtype=torch.float), # <- PyTorch loves float32 by default
                                    requires_grad=True) # <- can we update this value with gradient descent?))
    
        # Forward defines the computation in the model
        def forward(self, x: torch.Tensor) -> torch.Tensor: # <- "x" is the input data (e.g. training/testing features)
            return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)
  </code></pre>
</div>

<div class="note">
  <strong>Resource:</strong> We’ll use Python classes to build components for our neural network.

  If you’re new to Python class notation, I highly recommend checking out <a href="https://realpython.com/python3-object-oriented-programming/" target="_blank" rel="noopener noreferrer">
    Real Python's Object-Oriented Programming Guide
</a>
 in Python 3 guide and reviewing it a few times for a solid understanding.
</div>
<br>

<h3>PyTorch Model Building Essentials</h3>

<p>
  PyTorch has four essential modules that allow you to create almost any neural network you can imagine:
</p>
<li>
  torch.nn – For building and defining neural network layers.
</li>
<li>
  torch.optim – For optimizing model parameters during training.
</li>
<li>
  torch.utils.data.Dataset – For handling and customizing datasets.
</li>
<li>
  torch.utils.data.DataLoader – For efficiently loading data in batches.
</li>

<table>
  <thead>
      <tr>
          <th>PyTorch Module</th>
          <th>What Does It Do?</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>torch.nn</td>
          <td>Contains all of the building blocks for computational graphs (essentially a series of computations executed in a particular way).</td>
      </tr>
      <tr>
          <td>torch.nn.Parameter</td>
          <td>Stores tensors that can be used with nn.Module. If <code>requires_grad=True</code>, gradients (used for updating model parameters via gradient descent) are calculated automatically. This is often referred to as "autograd".</td>
      </tr>
      <tr>
          <td>torch.nn.Module</td>
          <td>The base class for all neural network modules, all the building blocks for neural networks are subclasses. If you're building a neural network in PyTorch, your models should subclass <code>nn.Module</code>. Requires a <code>forward()</code> method to be implemented.</td>
      </tr>
      <tr>
          <td>torch.optim</td>
          <td>Contains various optimization algorithms (these tell the model parameters stored in <code>nn.Parameter</code> how to best change to improve gradient descent and in turn reduce the loss).</td>
      </tr>
      <tr>
          <td>def forward()</td>
          <td>All <code>nn.Module</code> subclasses require a <code>forward()</code> method. This defines the computation that will take place on the data passed to the particular <code>nn.Module</code> (e.g., the linear regression formula).</td>
      </tr>
  </tbody>
</table>
<img
        src="model.png"
        class="centered-image"
      />

      <div class="note">
        <strong>Resource:</strong>See more of these essential modules and their use cases in the <a href="https://pytorch.org/tutorials/beginner/ptcheat.html" target="_blank" rel="noopener noreferrer">
          PyTorch Cheat Sheet.
      </a>
       in Python 3 guide and reviewing it a few times for a solid understanding.
      </div>
<br>
      <h3>Checking The Contents of a PyTorch Model</h3>
<p>
  Now that we've covered the essentials, let's create a model instance using the class we've defined. After that, we can check the model's parameters by calling .parameters().

This will give us insight into the weights and biases the model has learned so far. Let's dive in!
</p>
<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
# Set manual seed since nn.Parameter are randomly initialized
torch.manual_seed(42)

# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))
model_0 = LinearRegressionModel()

# Check the nn.Parameter(s) within the nn.Module subclass we created
list(model_0.parameters())

    </code>
<code>
  <pre>
[Parameter containing:
tensor([0.3367], requires_grad=True),
Parameter containing:
tensor([0.1288], requires_grad=True)]
 <div class="code-output"></div>
  </pre>
</code>

  </pre>


<br>

<p>
  We can also inspect the state of the model, which shows what the model contains, using the .state_dict() method.

This returns a dictionary of all the parameters (weights and biases) that the model holds, providing a more detailed view of the model's internal state.
</p>

</div>

<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
# List named parameters 
model_0.state_dict()

<code>
  <pre>
OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])
    <div class="code-output"></div>
  </pre>
</code>
  </code>
</pre>
</div>

<p>
Notice how the values for weights and biases from model_0.state_dict() come out as random float tensors? <br><br>

This happens because we initialized them using torch.randn(), which generates random values. <br><br>

The idea is to start with random parameters, then train the model to update these parameters so they fit the data well — ultimately moving toward the values we set when creating our straight-line data (the hardcoded weight and bias).
</p>


<br>
<div class="note">
  <strong>Exercise:</strong>Try changing the value of torch.manual_seed() in the cell above and see how it affects the weights and bias values.
</div>

<div class="note">
  <strong>Note:</strong>The torch.manual_seed() function ensures that the random initialization is reproducible. By setting different seed values, you can observe how the initial weights and biases vary each time, but they will remain consistent for the same seed value.
</div>
<br>
<h3>
  Making predictions using torch.inference_mode()</h3>

  <p>
To check how well the model is performing, we can pass the test data (X_test) through the model and see how closely it predicts y_test.
<br><br>
When we pass data to our model, it will go through the forward() method, which will execute the computation we've defined and produce predictions.
<br><br>
Now, let's go ahead and make some predictions!
  </p>

  <br><br>

  <div class="code-container">
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
# Make predictions with model
with torch.inference_mode(): 
    y_preds = model_0(X_test)

# Note: in older PyTorch code you might also see torch.no_grad()
# with torch.no_grad():
#   y_preds = model_0(X_test)
    </code>
  </pre>
  </div>
  <br>
  <p>
    Hmm, you probably noticed we used torch.inference_mode() as a context manager (with torch.inference_mode():) to make the predictions.
    <br><br>

As the name suggests, torch.inference_mode() is used when making predictions (inference) with a trained model.
<br><br>
It turns off certain things, like gradient tracking (which is necessary for training but not for inference), to make forward passes faster. This is why it’s used during inference—it helps improve efficiency by skipping unnecessary operations.
  </p>
<br>
<div class="note">
  <strong>Note:</strong> In older PyTorch code, you may also see torch.no_grad() being used for inference. While torch.inference_mode() and torch.no_grad() do similar things, torch.inference_mode() is newer, potentially faster and preferred. See this  <a href="https://x.com/PyTorch/status/1437838231505096708?s=20" target="_blank" rel="noopener noreferrer">
  Tweet from PyTorch
</a> for more.
</div>
<p>
  We've made some predictions now we will see how they look like
</p>
<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    # Check the predictions
    print(f"Number of testing samples: {len(X_test)}") 
    print(f"Number of predictions made: {len(y_preds)}")
    print(f"Predicted values:\n{y_preds}")
    <code>
      <pre>
        Number of testing samples: 10
        Number of predictions made: 10
        Predicted values:
        tensor([[0.3982],
                [0.4049],
                [0.4116],
                [0.4184],
                [0.4251],
                [0.4318],
                [0.4386],
                [0.4453],
                [0.4520],
                [0.4588]])
        <div class="code-output"></div>
      </pre>
    </code>
  </code>
</pre>
</div>
<p>
  Now we have made some predictions, let's visualize them to see how well our model is performing.
</p>

<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    plot_predictions(predictions=y_preds)
  </code>
</pre>
</div>
<img src="pred.png"  class="centered-image">

<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    y_test - y_preds
  </code>
  <code>
    <pre>
      tensor([[0.4618],
      [0.4691],
      [0.4764],
      [0.4836],
      [0.4909],
      [0.4982],
      [0.5054],
      [0.5127],
      [0.5200],
      [0.5272]])
      <div class="code-output"></div>
    </pre>
  </code>
</div>

<p>
  The difference between the actual values (y_test) and the predicted values (y_preds) is shown above. This difference is known as the loss, which we'll cover in the next section. 
  <br><br>
  Our model hasn't even look at the blue dots yet to learn the relationship between X and y. It's just guessing based on the random weights and biases we initialized it with. <br><br>
  It is time to change that!
</p>

<h2>3. Train a model</h2>
<p>
  Right now our model is making random predictions. We need to train it to make better predictions. <br><br>
  To do this, we need to update its internal parameters (weights and biases) so that it learns the relationship between X and y. <br><br>
  This is where the magic of deep learning happens! <br><br>
</p>

<h3>Creating a loss function and optimizer in PyTorch</h3>
<p>
  To train a model, we need two things: <br><br>
  <li>
    A loss function: This measures how far off our model's predictions are from the actual values.
  </li>
  <li>
    An optimizer: This adjusts the model's internal parameters (weights and biases) to reduce the loss.
  </li>
  <br>
  Let's dive into the code and create these two essential components!
</p>

<p>
  To improve our model, we need to define a loss function and an optimizer. The choice of these depends on the type of problem you're solving.
  For example, for a regression problem like ours, we can use the mean absolute error (MAE), which is under 'torch.nn.L1Loss()' in PyTorch as our loss function.
</p>

<br>

<img src="Screenshot 2025-02-08 105551.png"  class="centered-image">
<br>
<p>
  Mean absolute error (MAE, in PyTorch: torch.nn.L1Loss) measures the absolute difference between two points (predictions and labels) and then takes the mean across all examples.
</p>

<p>
  And we'll use SGD, <code class="code-style">torch.optim.SGD(params, lr)</code> where:
</p>
<code class="code-style">params </code>: is the target model parameters you'd like to optimize (e.g. the weights and bias values we randomly set before).
<br>
<code class="code-style">lr</code>: is the learning rate, which controls how much the model adjusts its parameters in response to the loss.


<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    # Create the loss function
    loss_fn = nn.L1Loss() # MAE loss is same as L1Loss
    
    # Create the optimizer
    optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize
                                lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))
  </code>
  <code>
    <pre>
$$$output$$$
           <div class="code-output"></div>
    </pre>
  </code>
</div>
<br>
<h3>Creating an optimization loop in PyTorch</h3>
<br>
<p>
  🎉 Now that we have a loss function and an optimizer, it’s time to create a training loop and a testing loop.
</p>


<li>
  Training Loop:  The model learns the relationships between features and labels by iterating through the training data.
</li>
<li>Testing Loop:The model evaluates its performance on unseen testing data to assess how well it has learned the patterns from the training data. </li>

<p>
  These are called "loops" because the model processes (loops through) each sample in the datasets. There is a very nice PyTorch optimization loop slogan to quickly memorize the steps: "Forward, Backward, Update, Repeat!" and a song too by Danial Bourkerl. 
</p>
<br>
<img src="song.png"  class="centered-image">
<br>
<h3>PyTorch Training Loop</h3>
<table>
  <thead>
    <tr>
      <th>Number</th>
      <th>Step Name</th>
      <th>What Does It Do?</th>
      <th>Code Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Forward Pass</td>
      <td>The model goes through all of the training data once, performing its <code>forward()</code> function calculations.</td>
      <td><code>model(x_train)</code></td>
    </tr>
    <tr>
      <td>2</td>
      <td>Calculate the Loss</td>
      <td>The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are.</td>
      <td><code>loss = loss_fn(y_pred, y_train)</code></td>
    </tr>
    <tr>
      <td>3</td>
      <td>Zero Gradients</td>
      <td>The optimizer's gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step.</td>
      <td><code>optimizer.zero_grad()</code></td>
    </tr>
    <tr>
      <td>4</td>
      <td>Perform Backpropagation on the Loss</td>
      <td>Computes the gradient of the loss with respect to every model parameter to be updated (each parameter with <code>requires_grad=True</code>). This is known as backpropagation, hence "backwards".</td>
      <td><code>loss.backward()</code></td>
    </tr>
    <tr>
      <td>5</td>
      <td>Update the Optimizer (Gradient Descent)</td>
      <td>Update the parameters with <code>requires_grad=True</code> with respect to the loss gradients in order to improve them.</td>
      <td><code>optimizer.step()</code></td>
    </tr>
  </tbody>
</table>
<br>
<img src="trainingLoop.png"  class="centered-image">
<br>
<div class="note">
  <strong>Note:</strong>Note: The above is just one example of how the steps could be ordered or described. With experience you'll find making PyTorch training loops can be quite flexible.

  And on the ordering of things, the above is a good default order but you may see slightly different orders. Some rules of thumb: <br>
  
  1. Calculate the loss (<code>loss = ...</code>) before performing backpropagation on it (<code>loss.backward()</code>). <br>
  2. Zero gradients (<code>optimizer.zero_grad()</code>) before computing the gradients of the loss with respect to every model parameter (<code>loss.backward()</code>).<br>
  3. Step the optimizer (<code>optimizer.step()</code>) after performing backpropagation on the loss (<code>loss.backward()</code>).
</div>
<br>
    
<h3>PyTorch Testing Loop</h3>


<p>
  As for the testing loop (evaluating loop), the typical steps include:
</p>

<table>
  <thead>
    <tr>
      <th>Number</th>
      <th>Step Name</th>
      <th>What Does It Do?</th>
      <th>Code Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Forward Pass</td>
      <td>The model goes through all of the testing data once, performing its <code>forward()</code> function calculations.</td>
      <td><code>model(x_test)</code></td>
    </tr>
    <tr>
      <td>2</td>
      <td>Calculate the Loss</td>
      <td>The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are.</td>
      <td><code>loss = loss_fn(y_pred, y_test)</code></td>
    </tr>
    <tr>
      <td>3</td>
      <td>Calculate Evaluation Metrics (Optional)</td>
      <td>Alongside the loss value, you may want to calculate other evaluation metrics such as accuracy on the test set.</td>
      <td><code>Custom functions</code></td>
    </tr>
  </tbody>
</table>

<p>
  During testing, backpropagation (<code class="code-style">loss.backward() </code>) and optimizer updates (<code class="code-style">optimizer.step() </code>) are not performed because the model's parameters remain unchanged. These parameters were already optimized during training. In the testing phase, our focus is solely on obtaining predictions from the model by running a forward pass over the test data.
</p>




<img src="testing.png"  class="centered-image">


<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    torch.manual_seed(42)

    # Set the number of epochs (how many times the model will pass over the training data)
    epochs = 100
    
    # Create empty loss lists to track values
    train_loss_values = []
    test_loss_values = []
    epoch_count = []
    
    for epoch in range(epochs):
        ### Training
    
        # Put model in training mode (this is the default state of a model)
        model_0.train()
    
        # 1. Forward pass on train data using the forward() method inside 
        y_pred = model_0(X_train)
        # print(y_pred)
    
        # 2. Calculate the loss (how different are our models predictions to the ground truth)
        loss = loss_fn(y_pred, y_train)
    
        # 3. Zero grad of the optimizer
        optimizer.zero_grad()
    
        # 4. Loss backwards
        loss.backward()
    
        # 5. Progress the optimizer
        optimizer.step()
    
        ### Testing
    
        # Put the model in evaluation mode
        model_0.eval()
    
        with torch.inference_mode():
          # 1. Forward pass on test data
          test_pred = model_0(X_test)
    
          # 2. Caculate loss on test data
          test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type
    
          # Print out what's happening
          if epoch % 10 == 0:
                epoch_count.append(epoch)
                train_loss_values.append(loss.detach().numpy())
                test_loss_values.append(test_loss.detach().numpy())
                print(f"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} ")
  </code>
  <code>
    <pre>
      Epoch: 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss: 0.48106518387794495 
      Epoch: 10 | MAE Train Loss: 0.1976713240146637 | MAE Test Loss: 0.3463551998138428 
      Epoch: 20 | MAE Train Loss: 0.08908725529909134 | MAE Test Loss: 0.21729660034179688 
      Epoch: 30 | MAE Train Loss: 0.053148526698350906 | MAE Test Loss: 0.14464017748832703 
      Epoch: 40 | MAE Train Loss: 0.04543796554207802 | MAE Test Loss: 0.11360953003168106 
      Epoch: 50 | MAE Train Loss: 0.04167863354086876 | MAE Test Loss: 0.09919948130846024 
      Epoch: 60 | MAE Train Loss: 0.03818932920694351 | MAE Test Loss: 0.08886633068323135 
      Epoch: 70 | MAE Train Loss: 0.03476089984178543 | MAE Test Loss: 0.0805937647819519 
      Epoch: 80 | MAE Train Loss: 0.03132382780313492 | MAE Test Loss: 0.07232122868299484 
      Epoch: 90 | MAE Train Loss: 0.02788739837706089 | MAE Test Loss: 0.06473556160926819 
           <div class="code-output"></div>
    </pre>
  </code>
</div>

  <p>
    Great! It seems like our loss is decreasing with each epoch. Let's visualize it with a plot to get a clearer picture.
  </p>
  <div class="code-container">
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
      # Plot the loss curves
      plt.plot(epoch_count, train_loss_values, label="Train loss")
      plt.plot(epoch_count, test_loss_values, label="Test loss")
      plt.title("Training and test loss curves")
      plt.ylabel("Loss")
      plt.xlabel("Epochs")
      plt.legend();
    </code>

  </div>
  <img src="plotloss.png"  class="centered-image">
  
  <p>
    Awesome! The loss curves indicate that the loss is gradually decreasing over time. Since loss represents how far off our model's predictions are, a lower loss means better performance. <br><br>

But what caused this improvement?
<br><br>

Thanks to the loss function and optimizer, the model's internal parameters—such as weights and biases—were adjusted to better capture the patterns in the data. <br><br>

Now, let's check our model's <code class="code-style">state_dict() </code> to see how closely the learned parameters match the original values we set for weights and biases.


  </p>

  <div class="code-container">
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
      # Find our model's learned parameters
      print("The model learned the following values for weights and bias:")
      print(model_0.state_dict())
      print("\nAnd the original values for weights and bias are:")
      print(f"weights: {weight}, bias: {bias}")
    </code>
    <code>
      <pre>
        The model learned the following values for weights and bias:
        OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3513]))])
        
        And the original values for weights and bias are:
        weights: 0.7, bias: 0.3
             <div class="code-output"></div>
      </pre>
    </code>
  </div>

  <p>
    The model has learned the relationship between X and y! The weights and bias values are now closer to the original values we set. <br><br>

    <br>
    It’s unlikely that the model will ever predict them with complete precision, especially with more complex datasets. But that’s perfectly fine—often, a close approximation is all we need to achieve great results. <br><br>

This is the essence of machine learning and deep learning: instead of manually determining the optimal values that define our data, we train a model to discover them automatically.
<br>
</p>

<h2>Making predictions with a trained PyTorch model (inference)</h2>
  
<p>Once you've trained a model, the next step is to use it for making predictions.</p>

<p>We've already seen a preview of this in the training and testing code, and the process outside of those loops follows a similar approach.</p>

<p>When performing inference (making predictions) with a PyTorch model, keep these three key points in mind:</p>

<ul>
    <li><strong>Switch the model to evaluation mode:</strong> Use <code>model.eval()</code>.</li>
    <li><strong>Use the inference mode context manager:</strong> Wrap your code in <code>with torch.inference_mode(): ...</code> to optimize performance.</li>
    <li><strong>Ensure consistency in device placement:</strong> The model and data should be on the same device (either all on the CPU or all on the GPU).</li>
</ul>

<p>The first two steps disable unnecessary calculations and settings that PyTorch typically applies during training, making inference faster. The third step prevents device-related errors that could arise from mixing CPU and GPU operations.</p>


<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    # 1. Set the model in evaluation mode
    model_0.eval()
    
    # 2. Setup the inference mode context manager
    with torch.inference_mode():
      # 3. Make sure the calculations are done with the model and data on the same device
      # in our case, we haven't setup device-agnostic code yet so our data and model are
      # on the CPU by default.
      # model_0.to(device)
      # X_test = X_test.to(device)
      y_preds = model_0(X_test)
    y_preds
  </code>
  <code>
    <pre>
      tensor([[0.8141],
      [0.8256],
      [0.8372],
      [0.8488],
      [0.8603],
      [0.8719],
      [0.8835],
      [0.8950],
      [0.9066],
      [0.9182]])
           <div class="code-output"></div>
    </pre>

    <br>

  </code>
</div>

<p>Nice! We've made some predictions with our trained model, now how do they look?</p>

<code class="code-style"> plot_predictions(predictions=y_preds)</code>

<img src="predictionss.png"  class="centered-image">


<br>
<p><strong>Awesome!</strong> Those red dots are now much closer than before!</p>

<p>Now, let's move on to the next step—saving and reloading a model in PyTorch.</p>


<h2>5. Saving and loading a PyTorch model</h2>


<p><strong>Once you've trained a PyTorch model, you'll likely want to save it and use it elsewhere.</strong></p>

    <p>For instance, you might train your model on Google Colab or a local machine with a GPU, but later, you may need to deploy it in an application where others can access it.</p>

    <p>Alternatively, you might want to store your model’s progress so you can resume training or testing at a later time.</p>

    <p>When it comes to saving and loading models in PyTorch, there are three key methods to be familiar with. These approaches are based on PyTorch’s official guide for saving and loading models.</p>

    <table>
      <thead>
        <tr>
          <th>PyTorch Method</th>
          <th>What Does It Do?</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>torch.save</code></td>
          <td>Saves a serialized object to disk using Python's pickle utility. It can be used to save models, tensors, and other Python objects such as dictionaries.</td>
        </tr>
        <tr>
          <td><code>torch.load</code></td>
          <td>Uses pickle's unpickling features to deserialize and load pickled Python object files (such as models, tensors, or dictionaries) into memory. It also allows specifying the device (CPU, GPU, etc.) where the object should be loaded.</td>
        </tr>
        <tr>
          <td><code>torch.nn.Module.load_state_dict</code></td>
          <td>Loads a model’s parameter dictionary using a saved <code>state_dict()</code> object, allowing for efficient restoration of trained model parameters.</td>
        </tr>
      </tbody>
    </table>
    
    <div class="note">
      <strong>Note:</strong>According to Python’s official documentation, the pickle module is not secure. This means you should only deserialize (load) data from trusted sources. The same applies when loading PyTorch models—always ensure that you are using saved models from reliable and verified sources.
  </div>

  <h2>Saving a PyTorch model's <code class="code-style">state_dict() </code> </h2>

 

  <p>The best practice for saving and loading a model for inference (making predictions) is to save and restore its <code>state_dict()</code>.</p>

  <p>Let's go through the process step by step:</p>

  <ol>
      <li><strong>Create a directory</strong> for storing models, naming it <code>models</code>, using Python's <code>pathlib</code> module.</li>
      <li><strong>Define a file path</strong> where the model will be saved.</li>
      <li><strong>Save the model's state dictionary</strong> using <code>torch.save(obj, f)</code>, where <code>obj</code> is the <code>state_dict()</code> of the model and <code>f</code> is the target file path.</li>
  </ol>

  <div class="note">
    <strong>Note:</strong>In PyTorch, it is standard practice to use .pt or .pth as file extensions when saving models or objects. For example, a typical saved model filename might be saved_model_01.pth.
</div>

<br>
<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    from pathlib import Path

    # 1. Create models directory 
    MODEL_PATH = Path("models")
    MODEL_PATH.mkdir(parents=True, exist_ok=True)
    
    # 2. Create model save path 
    MODEL_NAME = "01_pytorch_workflow_model_0.pth"
    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME
    
    # 3. Save the model state dict 
    print(f"Saving model to: {MODEL_SAVE_PATH}")
    torch.save(obj=model_0.state_dict(), # only saving the state_dict() only saves the models learned parameters
               f=MODEL_SAVE_PATH) 
  </code>
  <br>


</div>

<p>
  Saving model to: models/01_pytorch_workflow_model_0.pth
</p>

<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    # Check the saved file path
    !ls -l models/01_pytorch_workflow_model_0.pth
  </code>
  <code>
    <pre>
      -rw-rw-r-- 1 daniel daniel 1063 Nov 10 16:07 models/01_pytorch_workflow_model_0.pth
           <div class="code-output"></div>
    </pre>
  </code>
</div>



<h2>Loading a saved PyTorch model's <code class="code-style">state_dict() </code> </h2>

<p>Since we've now got a saved model <code class="code-style">state_dict()</code> at <code class="code-style">models/01_pytorch_workflow_model_0.pth</code>, we can load it using <code class="code-style">torch.nn.Module.load_state_dict(torch.load(f))</code>, where <code class="code-style">f</code> is the file path of our saved model <code class="code-style">state_dict()</code>.</p>

<p><strong>Why call <code class="code-style">torch.load()</code> inside <code class="code-style">torch.nn.Module.load_state_dict()</code>?</strong></p>

<p>Since we only saved the model’s <code class="code-style">state_dict()</code>, which is a dictionary containing the learned parameters, and not the entire model, we first need to load the <code class="code-style">state_dict()</code> using <code class="code-style">torch.load()</code>. Then, we pass that <code class="code-style">state_dict()</code> to a new instance of our model, which is a subclass of <code class="code-style">nn.Module</code>.</p>

<p><strong>Why not save the entire model?</strong></p>

<p>Saving the full model instead of just the <code class="code-style">state_dict()</code> might seem more straightforward. However, as the PyTorch documentation states:</p>

<p><em>The disadvantage of this approach (saving the whole model) is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved...</em></p>

<p>Because of this, using the entire model file in different projects or after modifying the directory structure can cause compatibility issues.</p>

<p>Instead, we use the more flexible approach of saving and loading just the <code class="code-style">state_dict()</code>, which is essentially a dictionary of model parameters.</p>

<p>Let's test this by creating another instance of <code class="code-style">LinearRegressionModel()</code>, which is a subclass of <code class="code-style">torch.nn.Module</code>. Since it's an instance of <code class="code-style">nn.Module</code>, it will have the built-in method <code class="code-style">load_state_dict()</code>.</p>




<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    # Instantiate a new instance of our model (this will be instantiated with random weights)
    loaded_model_0 = LinearRegressionModel()
    
    # Load the state_dict of our saved model (this will update the new instance of our model with trained weights)
    loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))
  </code>
  <code>
    <pre>
      < All keys matched successfully >
           <div class="code-output"></div>
    </pre>
  </code>
</div>


<p><strong>Excellent!</strong> It looks like things matched up.</p>

<p>Now, to test our loaded model, let's use it for inference (making predictions) on the test dataset.</p>

<div class="code-container">
  <button class="copy-button" onclick="copyCode(this)">Copy</button>
<pre>
  <code>
    # 1. Put the loaded model into evaluation mode
    loaded_model_0.eval()
    
    # 2. Use the inference mode context manager to make predictions
    with torch.inference_mode():
        loaded_model_preds = loaded_model_0(X_test) # perform a forward pass on the test data with the loaded model
  </code>
  <code>
    <pre>

           <div class="code-output"></div>
    </pre>
  </code>
</div>


<br>
<p>
  Now we've made some predictions with the loaded model, let's see if they're the same as the previous predictions.</p>


  <div class="code-container">
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
      # Compare previous model predictions with loaded model predictions (these should be the same)
      y_preds == loaded_model_preds
    </code>
    <code>
      <pre>
        tensor([[True],
        [True],
        [True],
        [True],
        [True],
        [True],
        [True],
        [True],
        [True],
        [True]])
             <div class="code-output"></div>
      </pre>
    </code>
  </div>
  

<br>
<p>
  Nice!
  
  It looks like the loaded model predictions are the same as the previous model predictions (predictions made prior to saving). This indicates our model is saving and loading as expected.</p>



<h2>Exercises:</h2>
<p><strong>Create a straight line dataset</strong></p>
<p>Use the linear regression formula: <code>weight * X + bias</code>.</p>
<ul>
    <li>Set <code>weight = 0.3</code> and <code>bias = 0.9</code>.</li>
    <li>Ensure there are at least 100 data points.</li>
</ul>

<p><strong>Split the dataset</strong></p>
<ul>
    <li>Divide the dataset into 80% training and 20% testing.</li>
</ul>

<p><strong>Visualize the data</strong></p>
<ul>
    <li>Plot the training and testing data to make the dataset more understandable.</li>
</ul>

<p><strong>Build a PyTorch model</strong></p>
<ul>
    <li>Subclass <code>nn.Module</code>.</li>
    <li>Inside, include a randomly initialized <code>nn.Parameter()</code> for weight and bias with <code>requires_grad=True</code>.</li>
    <li>Implement the <code>forward()</code> method to compute the linear regression function.</li>
</ul>

<p><strong>Initialize the model</strong></p>
<ul>
    <li>Create an instance of the model.</li>
    <li>Check its <code>state_dict()</code>.</li>
</ul>

<p><strong>Loss function and optimizer</strong></p>
<ul>
    <li>Use <code>nn.L1Loss()</code> as the loss function.</li>
    <li>Use <code>torch.optim.SGD(params, lr)</code> as the optimizer.</li>
    <li>Set the learning rate to <code>0.01</code>.</li>
    <li>Optimize the parameters of the model.</li>
</ul>

<p><strong>Training loop</strong></p>
<ul>
    <li>Train the model for 300 epochs.</li>
    <li>Test the model on the test dataset every 20 epochs.</li>
</ul>

<p><strong>Make predictions</strong></p>
<ul>
    <li>Use the trained model to make predictions on the test data.</li>
</ul>

<p><strong>Visualize the predictions</strong></p>
<ul>
    <li>Plot the predictions against the original training and testing data.</li>
    <li>Ensure the predictions are in the correct format (e.g., moved from GPU to CPU if necessary).</li>
</ul>

<p><strong>Save the trained model</strong></p>
<ul>
    <li>Save the model's <code>state_dict()</code> to a file.</li>
</ul>

<p><strong>Load the saved model</strong></p>
<ul>
    <li>Create a new instance of the model.</li>
    <li>Load the saved <code>state_dict()</code> into it.</li>
</ul>

<p><strong>Verify the loaded model</strong></p>
<ul>
    <li>Perform predictions with the loaded model on the test data.</li>
    <li>Confirm that the predictions match those from the original trained model.</li>
</ul>


<h2>Extra-curriculum:</h2>
<p><strong>Extra-curriculum</strong></p>

<ul>
    <li>Listen to <em>The Unofficial PyTorch Optimization Loop Song</em> to help remember the steps in a PyTorch training/testing loop.</li>
    <li>Read <em>What is torch.nn, really?</em> by Jeremy Howard for a deeper understanding of how one of the most important modules in PyTorch works.</li>
    <li>Spend 10 minutes exploring the <a href="https://pytorch.org/tutorials/beginner/ptcheat.html" target="_blank">PyTorch documentation cheatsheet</a> to get familiar with different PyTorch modules.</li>
    <li>Spend 10 minutes reading the <a href="https://pytorch.org/docs/stable/notes/serialization.html" target="_blank">loading and saving documentation</a> on the PyTorch website to understand the different saving and loading options available.</li>
    <li>Spend 1-2 hours learning about the internals of gradient descent and backpropagation, the key algorithms behind model learning:</li>
    <ul>
        <li>Read the <a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank">Wikipedia page for Gradient Descent</a>.</li>
        <li>Read <a href="https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-implementation-12b080fdce8a" target="_blank">Gradient Descent Algorithm — A Deep Dive</a> by Robert Kwiatkowski.</li>
        <li>Watch <a href="https://www.youtube.com/watch?v=IHZwWFHWa-w" target="_blank">Gradient Descent: How Neural Networks Learn</a> by 3Blue1Brown.</li>
        <li>Watch <a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U" target="_blank">What is Backpropagation Really Doing?</a> by 3Blue1Brown.</li>
        <li>Read the <a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank">Wikipedia page for Backpropagation</a>.</li>
    </ul>
</ul>




















  </body>
  <script src="02.js"></script>
</html>
