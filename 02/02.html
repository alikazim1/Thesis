<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
    <link rel="stylesheet" href="02.css" />
    <script src="script.js" defer></script>
    <!-- Link to the separate JS file -->
  </head>

  <body>
    <div class="navbar">
      <a href="index.html">Home</a>
      <a href="#about">About</a>
      <a href="#services">Services</a>
      <a href="#contact">Contact</a>
    </div>

    <div class="content">
      <h1>02. PyTorch Neural Network Classification</h1>

      <h2>What is a Classification problem?</h2>
      <p>
        A classification problem involves predicting whether something is one
        thing or another. <br />
        For example, you might want to:
      </p>

      <table>
        <thead>
          <tr>
            <th>Problem Type</th>
            <th>What Is It?</th>
            <th>Example</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Binary Classification</strong></td>
            <td>Target can be one of two options, e.g., yes or no.</td>
            <td>
              Predict whether or not someone has heart disease based on their
              health parameters.
            </td>
          </tr>
          <tr>
            <td><strong>Multi-Class Classification</strong></td>
            <td>Target can be one of more than two options.</td>
            <td>Decide whether a photo is of food, a person, or a dog.</td>
          </tr>
          <tr>
            <td><strong>Multi-Label Classification</strong></td>
            <td>Target can be assigned more than one option.</td>
            <td>
              Predict what categories should be assigned to a Wikipedia article
              (e.g., mathematics, science, & philosophy).
            </td>
          </tr>
        </tbody>
      </table>

      <img src="cl1.png" class="centered-image" />
      <br />
      <img src="cl2.png" class="centered-image" />

      <br />
      <p>
        Classification, along with regression (predicting a number, as covered
        in Notebook 01), is one of the most common types of machine learning
        problems. <br />
        <br />
        In this notebook, we’ll explore different classification problems using
        PyTorch. <br />
        <br />
        Specifically, we’ll focus on taking a set of inputs and predicting the
        class they belong to.
      </p>
      <br>
      <h2>What we are going to cover</h3>
        <p>In this notebook, we’ll revisit the PyTorch workflow introduced in Notebook 01, reinforcing the key steps and concepts</p>

        <img src="workflow.png" class="centered-image" />

<p>
    However, instead of predicting a straight line (a regression problem), we’ll focus on a classification problem.
</p>
<table>
    <tr>
        <th>Topic</th>
        <th>Contents</th>
    </tr>
    <tr>
        <td>0. Architecture of a classification neural network</td>
        <td>Neural networks can come in almost any shape or size, but they typically follow a similar floor plan.</td>
    </tr>
    <tr>
        <td>1. Getting binary classification data ready</td>
        <td>Data can be almost anything but to get started we're going to create a simple binary classification dataset.</td>
    </tr>
    <tr>
        <td>2. Building a PyTorch classification model</td>
        <td>Here we'll create a model to learn patterns in the data, we'll also choose a loss function, optimizer and build a training loop specific to classification.</td>
    </tr>
    <tr>
        <td>3. Fitting the model to data (training)</td>
        <td>We've got data and a model, now let's let the model (try to) find patterns in the (training) data.</td>
    </tr>
    <tr>
        <td>4. Making predictions and evaluating a model (inference)</td>
        <td>Our model's found patterns in the data, let's compare its findings to the actual (testing) data.</td>
    </tr>
    <tr>
        <td>5. Improving a model (from a model perspective)</td>
        <td>We've trained and evaluated a model but it's not working, let's try a few things to improve it.</td>
    </tr>
    <tr>
        <td>6. Non-linearity</td>
        <td>So far our model has only had the ability to model straight lines, what about non-linear (non-straight) lines?</td>
    </tr>
    <tr>
        <td>7. Replicating non-linear functions</td>
        <td>We used non-linear functions to help model non-linear data, but what do these look like?</td>
    </tr>
    <tr>
        <td>8. Putting it all together with multi-class classification</td>
        <td>Let's put everything we've done so far for binary classification together with a multi-class classification problem.</td>
    </tr>
</table>

<h2>0. Architecture of a classification neural network</h2>

<table>
    <thead>
      <tr>
        <th>Hyperparameter</th>
        <th>Binary Classification</th>
        <th>Multiclass Classification</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Input Layer Shape (<code class="code-style">in_features</code>)</td>
        <td>Same as number of features (e.g., 5 for age, sex, height, weight, smoking status</a> in heart disease prediction)</td>
        <td>Same as binary classification</td>
      </tr>
      <tr>
        <td><strong>Hidden Layer(s)</strong></td>
        <td>Problem specific, minimum = 1, maximum = unlimited</td>
        <td>Same as binary classification</td>
      </tr>
      <tr>
        <td><strong>Neurons Per Hidden Layer</strong></td>
        <td>Problem specific, generally 10 to 512</td>
        <td>Same as binary classification</td>
      </tr>
      <tr>
        <td><strong>Output Layer Shape (<code class="code-style">out_featues</code>)</strong></td>
        <td>1 (one class or the other)</td>
        <td>1 per class (e.g., 3 for food, person, or dog photo)</td>
      </tr>
      <tr>
        <td><strong>Hidden Layer Activation</strong></td>
        <td>Usually <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank">ReLU</a> (rectified linear unit) but can be many others</td>
        <td>Same as binary classification</td>
      </tr>
      <tr>
        <td><strong>Output Activation</strong></td>
        <td><a href="https://pytorch.org/docs/stable/generated/torch.sigmoid.html" target="_blank">Sigmoid</a> (<code>torch.sigmoid</code> in PyTorch)</td>
        <td><a href="https://pytorch.org/docs/stable/generated/torch.softmax.html" target="_blank">Softmax</a> (<code>torch.softmax</code> in PyTorch)</td>
      </tr>
      <tr>
        <td><strong>Loss Function</strong></td>
        <td><a href="https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html" target="_blank">Binary crossentropy</a> (<code>torch.nn.BCELoss</code> in PyTorch)</td>
        <td><a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html" target="_blank">Cross entropy</a> (<code>torch.nn.CrossEntropyLoss</code> in PyTorch)</td>
      </tr>
      <tr>
        <td><strong>Optimizer</strong></td>
        <td><a href="https://pytorch.org/docs/stable/optim.html" target="_blank">SGD (stochastic gradient descent), Adam</a> (see <code>torch.optim</code> for more options)</td>
        <td>Same as binary classification</td>
      </tr>
    </tbody>
  </table>
  

  <p>Of course, this ingredient list of classification neural network components will vary depending on the problem you're working on.</p>

  <p>But it's more than enough to get started.</p>
  
  <p>We're going to get hands-on with this setup throughout this notebook.</p>
  
  <h2>1. Make classification data and get it ready</h2>

  <p>Let’s start by creating some data. We’ll use Scikit-Learn’s 
    <code class="code-style">make_circles() </code>
method to generate two circles with differently colored dots.</p>



<div class="code-container">
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <pre><code>from sklearn.datasets import make_circles


        # Make 1000 samples 
        n_samples = 1000
        
        # Create circles
        X, y = make_circles(n_samples,
                            noise=0.03, # a little bit of noise to the dots
                            random_state=42) # keep random state so we get the same values</code></pre>
  </div>
  
  <p>
    Alright, now let's view the first 5 X and y values.</p>

    <div class="code-container">
        <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <pre>
        <code>
            print(f"First 5 X features:\n{X[:5]}")
            print(f"\nFirst 5 y labels:\n{y[:5]}")
        </code>
        <code>
          <pre>
            First 5 X features:
            [[ 0.75424625  0.23148074]
             [-0.75615888  0.15325888]
             [-0.81539193  0.17328203]
             [-0.39373073  0.69288277]
             [ 0.44220765 -0.89672343]]
            
            First 5 y labels:
            [1 1 1 1 0]
                 <div class="code-output"></div>
          </pre>
        </code>
      </div>
      
<p>
    It seems there are two X values for every one y value. Following the data explorer’s motto—visualize, visualize, visualize—let’s load the data into a pandas DataFrame for better visualization.
</p>

<div class="code-container">
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
        # Make DataFrame of circle data
        import pandas as pd
        circles = pd.DataFrame({"X1": X[:, 0],
            "X2": X[:, 1],
            "label": y
        })
        circles.head(10)
    </code>
    <code>
      <pre>
                X1	        X2      	label
        0	0.754246	0.231481	1
        1	-0.756159	0.153259	1
        2	-0.815392	0.173282	1
        3	-0.393731	0.692883	1
        4	0.442208	-0.896723	0
        5	-0.479646	0.676435	1
        6	-0.013648	0.803349	1
        7	0.771513	0.147760	1
        8	-0.169322	-0.793456	1
        9	-0.121486	1.021509	0
             <div class="code-output"></div>
      </pre>
    </code>
  </div>
  
  <p>
    
Each pair of X features (X1 and X2) has a corresponding label (y) of either 0 or 1. This indicates that our problem is a binary classification task, as there are only two possible classes.

Now, let’s check how many values belong to each class.
  </p>

  <div class="code-container">
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
  <pre>
    <code>
        # Check different labels
        circles.label.value_counts()
    </code>
    <code>
      <pre>
        label
        1    500
        0    500
        Name: count, dtype: int64
             <div class="code-output"></div>
      </pre>
    </code>
  </div>
  
<p>
    500 each, nice and balanced.

Let's plot them.
</p>


<div class="code-container">
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <pre><code># Visualize with a plot
        import matplotlib.pyplot as plt
        plt.scatter(x=X[:, 0], 
                    y=X[:, 1], 
                    c=y, 
                    cmap=plt.cm.RdYlBu);</code></pre>
  </div>
  




<img src="circle.png"  class="centered-image">

<p>Alright, we’ve got a problem to solve! Let’s figure out how to build a PyTorch neural network to classify the dots into red (0) or blue (1).</p>


<div class="note">
    <strong>Note:</strong>This dataset is often considered a toy problem in machine learning—a simple problem used for testing and experimentation. However, it captures the essence of classification: using numerical data to build a model that can classify inputs into distinct categories. In our case, the goal is to separate the data into red (0) or blue (1) dots.
</div>
<br>
  <h2>1.1 Input and Output Shapes</h2>

  <p>
    One of the most common errors in deep learning is <strong>shape errors</strong>. Mismatched tensor shapes or operations will cause your model to fail. These errors are inevitable, but you can minimize them by consistently checking the <strong>shapes of your data</strong>.
  </p>
  <p>
    A good practice is to focus on <strong>input and output shapes</strong>. Always ask:
  </p>
  <ul>
    <li><strong>What shape are my inputs?</strong></li>
    <li><strong>What shape are my outputs?</strong></li>
  </ul>
  <p>
    Let’s explore this further.
  </p>
  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Check the shapes of our features and labels
            X.shape, y.shape
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            ((1000, 2), (1000,))
          </code>
        </pre>
      </div>
    </div>
  </div>


  
 
  <p>
    The first dimension of <strong>X</strong> and <strong>y</strong> matches—there are 1000 samples for each. But what about the second dimension of <strong>X</strong>?
  </p>
  <p>
    To better understand the expected input and output shapes of your model, it’s helpful to examine the values and shapes of a <strong>single sample</strong> (both features and labels).
  </p>

  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
              # View the first example of features and labels
              X_sample = X[0]
              y_sample = y[0]
              print(f"Values for one sample of X: {X_sample} and the same for y: {y_sample}")
              print(f"Shapes for one sample of X: {X_sample.shape} and the same for y: {y_sample.shape}")
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
             
              Values for one sample of X: [0.75424625 0.23148074] and the same for y: 1
              Shapes for one sample of X: (2,) and the same for y: ()
          </code>
        </pre>
      </div>
    </div>
  </div>



<p>
    This tells us the second dimension for X means it has two features (vector) where as y has a single feature (scalar).</p>

    <p>

We have two inputs for one output.


</p>

<h2>1.2 Turn data into tensors and create train and test split</h2>

<p>
    Now that we’ve explored the shapes of our data, let’s prepare it for use with PyTorch and modeling. Specifically, we’ll need to:
  </p>

  <ul>
    <li>
      <strong>Convert Data to Tensors:</strong>
      <p>
        Currently, our data is in NumPy arrays. PyTorch prefers to work with <strong>PyTorch tensors</strong>, so we’ll convert our data accordingly.
      </p>
    </li>
    <li>
      <strong>Split Data into Training and Test Sets:</strong>
      <p>
        We’ll split our data into a <strong>training set</strong> (to train the model and learn patterns between <code>X</code> and <code>y</code>) and a <strong>test set</strong> (to evaluate the model’s performance on unseen data).
      </p>
    </li>
  </ul>

  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Turn data into tensors
            # Otherwise this causes issues with computations later on
            import torch
            X = torch.from_numpy(X).type(torch.float)
            y = torch.from_numpy(y).type(torch.float)
            
            # View the first five samples
            X[:5], y[:5]
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            (tensor([[ 0.7542,  0.2315],
            [-0.7562,  0.1533],
            [-0.8154,  0.1733],
            [-0.3937,  0.6929],
            [ 0.4422, -0.8967]]),
    tensor([1., 1., 1., 1., 0.]))
          </code>
        </pre>
      </div>
    </div>
  </div>


  <p>
    Now that our data is in tensor format, let’s split it into <strong>training</strong> and <strong>test sets</strong>.
  </p>
  <p>
    To do so, we’ll use the helpful function <code>train_test_split()</code> from <strong>Scikit-Learn</strong>.
  </p>
  <p>
    We’ll use <code>test_size=0.2</code> (80% training, 20% testing). Since the split happens randomly across the data, we’ll set <code>random_state=42</code> to ensure the split is reproducible.
  </p>





  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Split data into train and test sets
            from sklearn.model_selection import train_test_split
            
            X_train, X_test, y_train, y_test = train_test_split(X, 
                                                                y, 
                                                                test_size=0.2, # 20% test, 80% train
                                                                random_state=42) # make the random split reproducible
            
            len(X_train), len(X_test), len(y_train), len(y_test)
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            (800, 200, 800, 200)
          </code>
        </pre>
      </div>
    </div>
  </div>

<h2>2. Building a model</h2>

<p>
    We’ve got some data ready—now it’s time to <strong>build a model</strong>.
  </p>
  <p>
    We’ll break it down into a few parts:
  </p>
  <ul>
    <li>
      Setting up <strong>device agnostic code</strong> (so our model can run on CPU or GPU if it’s available).
    </li>
    <li>
      Constructing a model by subclassing <code>nn.Module</code>.
    </li>
    <li>
      Defining a <strong>loss function</strong> and <strong>optimizer</strong>.
    </li>
    <li>
      Creating a <strong>training loop</strong> (this’ll be in the next section).
    </li>
  </ul>
  <p>
    The good news is we’ve been through all of the above steps before in <strong>notebook 01</strong>.
  </p>
  <p>
    Except now we’ll be adjusting them so they work with a <strong>classification dataset</strong>.
  </p>
  <p>
    Let’s start by importing <code>PyTorch</code> and <code>torch.nn</code>, as well as setting up <strong>device agnostic code</strong>.
  </p>



  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Standard PyTorch imports
            import torch
            from torch import nn
            
            # Make device agnostic code
            device = "cuda" if torch.cuda.is_available() else "cpu"
            device
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            'cuda'
          </code>
        </pre>
      </div>
    </div>
  </div>
  <p>
    Excellent! Now that the device is set up, we can use it for any data or models we create. PyTorch will handle it on the <strong>CPU</strong> (default) or <strong>GPU</strong> if it’s available.
  </p>
  <p>
    How about we create a model?
  </p>
  <p>
    We’ll want a model capable of handling our <code>X</code> data as inputs and producing something in the shape of our <code>y</code> data as outputs.
  </p>
  <p>
    In other words, given <code>X</code> (features), we want our model to predict <code>y</code> (label).
  </p>
  <p>
    This setup, where you have <strong>features</strong> and <strong>labels</strong>, is referred to as <strong>supervised learning</strong>. This is because your data is telling your model what the outputs should be given a certain input.
  </p>
  <p>
    To create such a model, it’ll need to handle the <strong>input and output shapes</strong> of <code>X</code> and <code>y</code>.
  </p>
  <p>
    Remember how I said input and output shapes are important? Here we’ll see why.
  </p>
  <p>
    Let’s create a model class that:
  </p>
  <ul>
    <li>
      Subclasses <code>nn.Module</code> (almost all PyTorch models are subclasses of <code>nn.Module</code>).
    </li>
    <li>
      Creates <strong>2 <code>nn.Linear</code> layers</strong> in the constructor capable of handling the input and output shapes of <code>X</code> and <code>y</code>.
    </li>
    <li>
      Defines a <code>forward()</code> method containing the <strong>forward pass computation</strong> of the model.
    </li>
    <li>
      Instantiates the model class and sends it to the <strong>target device</strong>.
    </li>
  </ul>

  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # 1. Construct a model class that subclasses nn.Module
            class CircleModelV0(nn.Module):
                def __init__(self):
                    super().__init__()
                    # 2. Create 2 nn.Linear layers capable of handling X and y input and output shapes
                    self.layer_1 = nn.Linear(in_features=2, out_features=5) # takes in 2 features (X), produces 5 features
                    self.layer_2 = nn.Linear(in_features=5, out_features=1) # takes in 5 features, produces 1 feature (y)
                
                # 3. Define a forward method containing the forward pass computation
                def forward(self, x):
                    # Return the output of layer_2, a single feature, the same shape as y
                    return self.layer_2(self.layer_1(x)) # computation goes through layer_1 first then the output of layer_1 goes through layer_2
            
            # 4. Create an instance of the model and send it to target device
            model_0 = CircleModelV0().to(device)
            model_0
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            CircleModelV0(
                (layer_1): Linear(in_features=2, out_features=5, bias=True)
                (layer_2): Linear(in_features=5, out_features=1, bias=True)
              )
          </code>
        </pre>
      </div>
    </div>
  </div>

  <p>
    What’s going on here?
  </p>
  <p>
    We’ve seen a few of these steps before. The only major change is what’s happening between <code>self.layer_1</code> and <code>self.layer_2</code>.
  </p>
  <p>
    <code>self.layer_1</code> takes <strong>2 input features</strong> (<code>in_features=2</code>) and produces <strong>5 output features</strong> (<code>out_features=5</code>).
  </p>
  <p>
    This is known as having <strong>5 hidden units</strong> or <strong>neurons</strong>.
  </p>
  <p>
    This layer turns the input data from having <strong>2 features</strong> to <strong>5 features</strong>.
  </p>
  <p>
    Why do this?
  </p>
  <p>
    This allows the model to learn patterns from <strong>5 numbers</strong> rather than just <strong>2 numbers</strong>, potentially leading to better outputs.
  </p>
  <p>
    I say <strong>potentially</strong> because sometimes it doesn’t work.
  </p>
  <p>
    The number of hidden units you can use in neural network layers is a <strong>hyperparameter</strong> (a value you can set yourself), and there’s no set-in-stone value you have to use.
  </p>
  <p>
    Generally, <strong>more is better</strong>, but there’s also such a thing as <strong>too much</strong>. The amount you choose will depend on your model type and the dataset you’re working with.
  </p>
  <p>
    Since our dataset is small and simple, we’ll keep it small.
  </p>
  <p>
    The only rule with hidden units is that the next layer, in our case, <code>self.layer_2</code>, has to take the same <code>in_features</code> as the previous layer’s <code>out_features</code>.
  </p>
  <p>
    That’s why <code>self.layer_2</code> has <code>in_features=5</code>—it takes the <code>out_features=5</code> from <code>self.layer_1</code> and performs a linear computation on them, turning them into <code>out_features=1</code> (the same shape as <code>y</code>).
  </p>



  <img src="nn.png"  class="centered-image">


  <p>
    A visual example of what a similar classification neural network to the one we’ve just built looks like. Try creating one of your own on the <a href="https://playground.tensorflow.org/" target="_blank">TensorFlow Playground website</a>.
  </p>
  <p>
    You can also do the same as above using <code>nn.Sequential</code>.
  </p>
  <p>
    <code>nn.Sequential</code> performs a forward pass computation of the input data through the layers in the order they appear.
  </p>


  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Replicate CircleModelV0 with nn.Sequential
            model_0 = nn.Sequential(
                nn.Linear(in_features=2, out_features=5),
                nn.Linear(in_features=5, out_features=1)
            ).to(device)
            
            model_0
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            Sequential(
                (0): Linear(in_features=2, out_features=5, bias=True)
                (1): Linear(in_features=5, out_features=1, bias=True)
              )
          </code>
        </pre>
      </div>
    </div>
  </div>


  <p>
    Woah, that looks much simpler than subclassing <code>nn.Module</code>. Why not just always use <code>nn.Sequential</code>?
  </p>
  <p>
    <code>nn.Sequential</code> is fantastic for straightforward computations. However, as the name suggests, it always runs in sequential order.
  </p>
  <p>
    If you'd like something more complex to happen (rather than just straightforward sequential computation), you'll need to define your own custom <code>nn.Module</code> subclass.
  </p>
  <p>
    Now that we've got a model, let's see what happens when we pass some data through it.
  </p>



  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Make predictions with the model
            untrained_preds = model_0(X_test.to(device))
            print(f"Length of predictions: {len(untrained_preds)}, Shape: {untrained_preds.shape}")
            print(f"Length of test samples: {len(y_test)}, Shape: {y_test.shape}")
            print(f"\nFirst 10 predictions:\n{untrained_preds[:10]}")
            print(f"\nFirst 10 test labels:\n{y_test[:10]}")
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            Length of predictions: 200, Shape: torch.Size([200, 1])
            Length of test samples: 200, Shape: torch.Size([200])
            
            First 10 predictions:
            tensor([[0.0555],
                    [0.0169],
                    [0.2254],
                    [0.0071],
                    [0.3345],
                    [0.3101],
                    [0.1151],
                    [0.1840],
                    [0.2205],
                    [0.0156]], device='cuda:0', grad_fn=<SliceBackward0>)
            
            First 10 test labels:
            tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0.])
          </code>
        </pre>
      </div>
    </div>
  </div>

  <p>
    Hmm, it seems there are the same number of predictions as there are test labels, but the predictions don’t look like they’re in the same form or shape as the test labels.
  </p>
  <p>
    We’ve got a couple of steps we can take to fix this. We’ll explore these later on.
  </p>


<h2>2.1 Setup loss function and optimizer</h2>

<p>
    In notebook 01, we set up a loss (criterion or cost function) and optimizer. Different problem types require different loss functions.
  </p>
  <p>
    For regression (predicting a number), use mean absolute error (MAE) loss. For binary classification (like ours), binary cross-entropy is common.
  </p>
  <p>
    The same optimizer, such as SGD or Adam, can often be used across various problem types.
  </p>




  <table border="1" cellspacing="0" cellpadding="10" style="width: 100%; border-collapse: collapse;">
    <thead>
      <tr>
        <th>Loss function/Optimizer</th>
        <th>Problem type</th>
        <th>PyTorch Code</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Stochastic Gradient Descent (SGD) optimizer</td>
        <td>Classification, regression, many others.</td>
        <td>torch.optim.SGD()</td>
      </tr>
      <tr>
        <td>Adam Optimizer</td>
        <td>Classification, regression, many others.</td>
        <td>torch.optim.Adam()</td>
      </tr>
      <tr>
        <td>Binary cross entropy loss</td>
        <td>Binary classification</td>
        <td>torch.nn.BCELossWithLogits or torch.nn.BCELoss</td>
      </tr>
      <tr>
        <td>Cross entropy loss</td>
        <td>Multi-class classification</td>
        <td>torch.nn.CrossEntropyLoss</td>
      </tr>
      <tr>
        <td>Mean absolute error (MAE) or L1 Loss</td>
        <td>Regression</td>
        <td>torch.nn.L1Loss</td>
      </tr>
      <tr>
        <td>Mean squared error (MSE) or L2 Loss</td>
        <td>Regression</td>
        <td>torch.nn.MSELoss</td>
      </tr>
    </tbody>
  </table>
  
  <p><strong>Common Loss Functions and Optimizers:</strong></p>
  <p>There are many loss functions and optimizers, but these are some of the most common you'll encounter.</p>
  
  <p><strong>Binary Cross Entropy Loss</strong> is used for binary classification problems.</p>
  
  <p><strong>Loss Functions:</strong> 
    A loss function (or "criterion") measures how wrong your model's predictions are. The higher the loss, the worse your model.
  </p>

  <p><strong>PyTorch has two Binary Cross Entropy implementations:</strong></p>
  <ul>
    <li><strong>torch.nn.BCELoss()</strong> - Measures the binary cross entropy between target (label) and input (features).</li>
    <li><strong>torch.nn.BCEWithLogitsLoss()</strong> - Includes a built-in sigmoid layer (nn.Sigmoid), making it more numerically stable.</li>
  </ul>

  <p><strong>Which one to use?</strong> 
    <br>Generally, <strong>torch.nn.BCEWithLogitsLoss()</strong> is a better option due to its numerical stability.
  </p>

  <p><strong>For the optimizer:</strong> We'll use <strong>torch.optim.SGD()</strong> with a learning rate of 0.1 to optimize the model parameters.</p>


  <div class="note">
    <strong>Note:</strong>There are discussions around the use of nn.BCELoss vs. nn.BCEWithLogitsLoss, but it becomes clearer with practice.
</div>




<div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Create a loss function
            # loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in
            loss_fn = nn.BCEWithLogitsLoss() # BCEWithLogitsLoss = sigmoid built-in
            
            # Create an optimizer
            optimizer = torch.optim.SGD(params=model_0.parameters(), 
                                        lr=0.1)
          </code>
        </pre>
      </div>
    </div>
  </div>
  
  <p><strong>Creating an Evaluation Metric</strong></p>
  
  <p>While a loss function measures how wrong a model is, an evaluation metric shows how right it is. Both offer different perspectives, helping to assess performance more effectively.</p>

  <p><strong>Accuracy</strong> is a common metric for classification problems. It is calculated as:</p>
  
  <p><strong>Accuracy = (Correct Predictions / Total Predictions) × 100%</strong></p>

  <p>For example, if a model correctly predicts 99 out of 100 samples, its accuracy is 99%.</p>

  <p>Now, let's write a function to calculate accuracy.</p>



  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Create a loss function
# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in
loss_fn = nn.BCEWithLogitsLoss() # BCEWithLogitsLoss = sigmoid built-in

# Create an optimizer
optimizer = torch.optim.SGD(params=model_0.parameters(), 
                            lr=0.1)
          </code>
        </pre>
      </div>
    </div>
  </div>
  

  <h3>Evaluation Metric</h3>
  <p>An evaluation metric provides another perspective on model performance.</p>
  <p><strong>Loss function</strong> measures how wrong a model is, while an <strong>evaluation metric</strong> shows how right it is. Both offer valuable insights.</p>
  
  <h4>Accuracy</h4>
  <p>Accuracy is a common metric for classification, calculated as:</p>
  <p><strong>Accuracy = (Correct Predictions / Total Predictions) × 100%</strong></p>
  
  <p>For example, a model with 99 correct predictions out of 100 has an accuracy of 99%.</p>
  
  <p>Now, let's implement an accuracy function.</p>




  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Calculate accuracy (a classification metric)
def accuracy_fn(y_true, y_pred):
    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal
    acc = (correct / len(y_pred)) * 100 
    return acc
          </code>
        </pre>
      </div>
    </div>
  </div>
  

<p>
    Excellent! We can now use this function whilst training our model to measure it's performance alongside the loss.
</p>



<h2>3. Train model</h2>

<h3>
    3.1 Going from raw model outputs to predicted labels (logits -> prediction probabilities -> prediction labels)</h3>

    <p>Before starting the training loop, let's check what the model outputs during the forward pass.</p>
    <p>The <code>forward()</code> method defines the forward pass, where input data moves through the model to generate predictions.</p>
    <p>Let's pass some data into the model to see the results.</p>

    <div class="code-container">
        <!-- Input Block with Colab Button after the label -->
        <div class="code-block">
          <div class="input-label">
            Input Code:
            <!-- Colab Button after the label -->
            <a
              href="https://colab.research.google.com/"
              target="_blank"
              class="colab-button"
            >
              <img
                src="https://colab.research.google.com/assets/colab-badge.svg"
                alt="Open In Colab"
              />
            </a>
          </div>
          <button class="copy-button" onclick="copyCode(this)">Copy</button>
          <div class="code-scroll">
            <pre>
              <code class="code-style">
                # View the frist 5 outputs of the forward pass on the test data
                y_logits = model_0(X_test.to(device))[:5]
                y_logits
              </code>
            </pre>
          </div>
        </div>
    
        <!-- Output Block with Colab Button after the label -->
        <div class="code-block">
          <div class="output-label">
            Output Code:
            <!-- Colab Button after the label -->
            <a
              href="https://colab.research.google.com/"
              target="_blank"
              class="colab-button"
            >
              <img
                src="https://colab.research.google.com/assets/colab-badge.svg"
                alt="Open In Colab"
              />
            </a>
          </div>
          <button class="copy-button" onclick="copyCode(this)">Copy</button>
          <div class="code-scroll">
            <pre>
              <code class="code-style">
                tensor([[0.0555],
                [0.0169],
                [0.2254],
                [0.0071],
                [0.3345]], device='cuda:0', grad_fn=<SliceBackward0>)
              </code>
            </pre>
          </div>
        </div>
      </div>


      <p>Since our model hasn't been trained, its outputs are essentially random.</p>
      <p>But what are these outputs?</p>
      <p>They come from the <code>forward()</code> method, which applies two layers of <code>nn.Linear()</code>. Internally, this follows the equation:</p>
      <p>$$ \mathbf{y} = x \cdot \mathbf{Weights}^T + \mathbf{bias} $$</p>
      <p>The raw outputs of this equation (<code>y</code>), and thus the raw outputs of our model, are called <strong>logits</strong>.</p>
      <p>These logits are what our model produces when it takes input data (<code>x</code> in the equation or <code>X_test</code> in the code).</p>
      <p>However, logits are difficult to interpret. We need values comparable to our true labels.</p>
      <p>To convert logits into a more useful form, we can apply the <strong>sigmoid activation function</strong>.</p>
      <p>Let's try it out.</p>




      <div class="code-container">
        <!-- Input Block with Colab Button after the label -->
        <div class="code-block">
          <div class="input-label">
            Input Code:
            <!-- Colab Button after the label -->
            <a
              href="https://colab.research.google.com/"
              target="_blank"
              class="colab-button"
            >
              <img
                src="https://colab.research.google.com/assets/colab-badge.svg"
                alt="Open In Colab"
              />
            </a>
          </div>
          <button class="copy-button" onclick="copyCode(this)">Copy</button>
          <div class="code-scroll">
            <pre>
              <code class="code-style">
                # Use sigmoid on model logits
                y_pred_probs = torch.sigmoid(y_logits)
                y_pred_probs
              </code>
            </pre>
          </div>
        </div>
  
        <!-- Output Block with Colab Button after the label -->
        <div class="code-block">
          <div class="output-label">
            Output Code:
            <!-- Colab Button after the label -->
            <a
              href="https://colab.research.google.com/"
              target="_blank"
              class="colab-button"
            >
              <img
                src="https://colab.research.google.com/assets/colab-badge.svg"
                alt="Open In Colab"
              />
            </a>
          </div>
          <button class="copy-button" onclick="copyCode(this)">Copy</button>
          <div class="code-scroll">
            <pre>
              <code class="code-style">
                tensor([[0.5139],
                [0.5042],
                [0.5561],
                [0.5018],
                [0.5829]], device='cuda:0', grad_fn=<SigmoidBackward0>)
              </code>
            </pre>
          </div>
        </div>
      </div>


      <p>Now, the outputs have some consistency, though they are still random.</p>
      <p>They are now in the form of prediction probabilities (<code>y_pred_probs</code>), representing how much the model believes a data point belongs to one class or another.</p>
      <p>Since we're working with binary classification, the ideal outputs are <strong>0</strong> or <strong>1</strong>.</p>
      <p>These values act as a decision boundary:</p>
      <ul>
        <li>The closer to <strong>0</strong>, the more the model believes the sample belongs to class 0.</li>
        <li>The closer to <strong>1</strong>, the more the model believes the sample belongs to class 1.</li>
      </ul>
      <p>Specifically:</p>
      <ul>
        <li>If <code>y_pred_probs >= 0.5</code>, then <code>y = 1</code> (class 1).</li>
        <li>If <code>y_pred_probs < 0.5</code>, then <code>y = 0</code> (class 0).</li>
      </ul>
      <p>To convert prediction probabilities into class labels, we can round the outputs of the sigmoid activation function.</p>









      <div class="code-container">
        <!-- Input Block with Colab Button after the label -->
        <div class="code-block">
          <div class="input-label">
            Input Code:
            <!-- Colab Button after the label -->
            <a
              href="https://colab.research.google.com/"
              target="_blank"
              class="colab-button"
            >
              <img
                src="https://colab.research.google.com/assets/colab-badge.svg"
                alt="Open In Colab"
              />
            </a>
          </div>
          <button class="copy-button" onclick="copyCode(this)">Copy</button>
          <div class="code-scroll">
            <pre>
              <code class="code-style">
                # Find the predicted labels (round the prediction probabilities)
                y_preds = torch.round(y_pred_probs)
                
                # In full
                y_pred_labels = torch.round(torch.sigmoid(model_0(X_test.to(device))[:5]))
                
                # Check for equality
                print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))
                
                # Get rid of extra dimension
                y_preds.squeeze()
              </code>
            </pre>
          </div>
        </div>
  
        <!-- Output Block with Colab Button after the label -->
        <div class="code-block">
          <div class="output-label">
            Output Code:
            <!-- Colab Button after the label -->
            <a
              href="https://colab.research.google.com/"
              target="_blank"
              class="colab-button"
            >
              <img
                src="https://colab.research.google.com/assets/colab-badge.svg"
                alt="Open In Colab"
              />
            </a>
          </div>
          <button class="copy-button" onclick="copyCode(this)">Copy</button>
          <div class="code-scroll">
            <pre>
              <code class="code-style">
                tensor([True, True, True, True, True], device='cuda:0')
                tensor([1., 1., 1., 1., 1.], device='cuda:0', grad_fn=<SqueezeBackward0>)
              </code>
            </pre>
          </div>
        </div>
      </div>

<p>
    
Excellent! Now it looks like our model's predictions are in the same form as our truth labels (y_test).
</p>



<code class="code-style"> y_test[:5]</code>
<code class="code-style"> output: tensor([1., 0., 1., 0., 1.])</code>


<p>This allows us to compare our model's predictions with the test labels to evaluate its performance.</p>
<p>To summarize:</p>
<ul>
  <li>We converted the model's raw outputs (logits) into prediction probabilities using a sigmoid activation function.</li>
  <li>We then transformed the prediction probabilities into class labels by rounding them.</li>
</ul>



<div class="note">
    <strong>Note:</strong>The use of the sigmoid activation function is often only for binary classification logits. For multi-class classification, we'll be looking at using the softmax activation function (this will come later on). <br><br>

    And the use of the sigmoid activation function is not required when passing our model's raw outputs to the nn.BCEWithLogitsLoss (the "logits" in logits loss is because it works on the model's raw logits output), this is because it has a sigmoid function built-in.
</div>


<h2>3.2 Building a training and test loop</h2>



<p>Now that we've covered how to convert raw model outputs into prediction labels, it's time to build a training loop.</p>
  <p>We'll train for 100 epochs and display the model's progress every 10 epochs.</p>




<div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            torch.manual_seed(42)

            # Set the number of epochs
            epochs = 100
            
            # Put data to target device
            X_train, y_train = X_train.to(device), y_train.to(device)
            X_test, y_test = X_test.to(device), y_test.to(device)
            
            # Build training and evaluation loop
            for epoch in range(epochs):
                ### Training
                model_0.train()
            
                # 1. Forward pass (model outputs raw logits)
                y_logits = model_0(X_train).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device 
                y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls
              
                # 2. Calculate loss/accuracy
                # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()
                #                y_train) 
                loss = loss_fn(y_logits, # Using nn.BCEWithLogitsLoss works with raw logits
                               y_train) 
                acc = accuracy_fn(y_true=y_train, 
                                  y_pred=y_pred) 
            
                # 3. Optimizer zero grad
                optimizer.zero_grad()
            
                # 4. Loss backwards
                loss.backward()
            
                # 5. Optimizer step
                optimizer.step()
            
                ### Testing
                model_0.eval()
                with torch.inference_mode():
                    # 1. Forward pass
                    test_logits = model_0(X_test).squeeze() 
                    test_pred = torch.round(torch.sigmoid(test_logits))
                    # 2. Caculate loss/accuracy
                    test_loss = loss_fn(test_logits,
                                        y_test)
                    test_acc = accuracy_fn(y_true=y_test,
                                           y_pred=test_pred)
            
                # Print out what's happening every 10 epochs
                if epoch % 10 == 0:
                    print(f"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%")
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            Epoch: 0 | Loss: 0.70034, Accuracy: 50.00% | Test loss: 0.69484, Test acc: 52.50%
            Epoch: 10 | Loss: 0.69718, Accuracy: 53.75% | Test loss: 0.69242, Test acc: 54.50%
            Epoch: 20 | Loss: 0.69590, Accuracy: 51.12% | Test loss: 0.69161, Test acc: 53.50%
            Epoch: 30 | Loss: 0.69530, Accuracy: 50.62% | Test loss: 0.69136, Test acc: 53.00%
            Epoch: 40 | Loss: 0.69497, Accuracy: 49.75% | Test loss: 0.69131, Test acc: 53.50%
            Epoch: 50 | Loss: 0.69474, Accuracy: 50.12% | Test loss: 0.69134, Test acc: 53.50%
            Epoch: 60 | Loss: 0.69457, Accuracy: 49.88% | Test loss: 0.69139, Test acc: 53.50%
            Epoch: 70 | Loss: 0.69442, Accuracy: 49.62% | Test loss: 0.69146, Test acc: 54.00%
            Epoch: 80 | Loss: 0.69430, Accuracy: 49.62% | Test loss: 0.69153, Test acc: 54.50%
            Epoch: 90 | Loss: 0.69418, Accuracy: 49.62% | Test loss: 0.69161, Test acc: 54.50%
          </code>
        </pre>
      </div>
    </div>
  </div>





  <p>What do you notice about our model's performance?</p>
  <p>It completed training and testing, but the results haven't improved significantly.</p>
  <p>The accuracy remains around 50% for each data split.</p>
  <p>Since this is a balanced binary classification problem, the model is performing no better than random guessing. With 500 samples per class, always predicting class 1 would still yield 50% accuracy.</p>



<h2>4. Make predictions and evaluate the model</h2>

<p>The metrics suggest our model is randomly guessing.</p>
<p>How can we investigate further?</p>
<p>Let's follow the data explorer's motto: <strong>"Visualize, visualize, visualize!"</strong></p>
<p>We'll plot our model's predictions, the input data, and the decision boundary between class 0 and class 1.</p>
<p>To do this, we'll download and import the <code>helper_functions.py</code> script from the 
  <a href="https://github.com/mrdbourke/pytorch-deep-learning" target="_blank">Learn PyTorch for Deep Learning repo</a>.
</p>
<p>This script contains <code>plot_decision_boundary()</code>, a function that creates a NumPy meshgrid to visually show where our model predicts different classes.</p>
<p>We'll also use <code>plot_predictions()</code>, which we wrote in notebook 01.</p>




<div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            import requests
            from pathlib import Path 
            
            # Download helper functions from Learn PyTorch repo (if not already downloaded)
            if Path("helper_functions.py").is_file():
              print("helper_functions.py already exists, skipping download")
            else:
              print("Downloading helper_functions.py")
              request = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py")
              with open("helper_functions.py", "wb") as f:
                f.write(request.content)
            
            from helper_functions import plot_predictions, plot_decision_boundary
          </code>
        </pre>
      </div>
    </div>
  </div>
  

<p>helper_functions.py already exists, skipping download</p>


<div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Plot decision boundaries for training and test sets
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title("Train")
plot_decision_boundary(model_0, X_train, y_train)
plt.subplot(1, 2, 2)
plt.title("Test")
plot_decision_boundary(model_0, X_test, y_test)
          </code>
        </pre>
      </div>
    </div>
  </div>
  
  <img src="traintest.png"  class="centered-image">


  <p>Oh wow, it seems we've found the cause of the model's performance issue.</p>
  <p>It's trying to separate the red and blue dots using a straight line, which explains the 50% accuracy.</p>
  <p>Since the data is circular, a straight line can only cut it down the middle at best.</p>
  <p>In machine learning terms, this is underfitting. Our model isn't learning the predictive patterns from the data.</p>
  <p>So, how can we improve this?</p>


  <h2>5. Improving a model (from a model perspective)</h2>

  <p>Let's try to fix our model's underfitting problem.</p>
  <p>Focusing specifically on the model (not the data), there are a few ways we could do this.</p>

  <table>
    <thead>
      <tr>
        <th>Model Improvement Technique*</th>
        <th>What does it do?</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Add more layers</td>
        <td>Each layer potentially increases the learning capabilities of the model with each layer being able to learn some kind of new pattern in the data. More layers are often referred to as making your neural network deeper.</td>
      </tr>
      <tr>
        <td>Add more hidden units</td>
        <td>Similar to the above, more hidden units per layer means a potential increase in learning capabilities of the model. More hidden units are often referred to as making your neural network wider.</td>
      </tr>
      <tr>
        <td>Fitting for longer (more epochs)</td>
        <td>Your model might learn more if it had more opportunities to look at the data.</td>
      </tr>
      <tr>
        <td>Changing the activation functions</td>
        <td>Some data just can't be fit with only straight lines (like what we've seen), using non-linear activation functions can help with this (hint, hint).</td>
      </tr>
      <tr>
        <td>Change the learning rate</td>
        <td>Less model specific, but still related, the learning rate of the optimizer decides how much a model should change its parameters each step, too much and the model overcorrects, too little and it doesn't learn enough.</td>
      </tr>
      <tr>
        <td>Change the loss function</td>
        <td>Again, less model specific but still important, different problems require different loss functions. For example, a binary cross entropy loss function won't work with a multi-class classification problem.</td>
      </tr>
      <tr>
        <td>Use transfer learning</td>
        <td>Take a pretrained model from a problem domain similar to yours and adjust it to your own problem. We cover transfer learning in notebook 06.</td>
      </tr>
    </tbody>
  </table>
  

  <div class="note">
    <strong>Note:</strong>*because you can adjust all of these by hand, they're referred to as hyperparameters.

    And this is also where machine learning's half art half science comes in, there's no real way to know here what the best combination of values is for your project, best to follow the data scientist's motto of "experiment, experiment, experiment".
</div>


<p>Let's see what happens if we add an extra layer to our model, fit for longer (epochs=1000 instead of epochs=100) and increase the number of hidden units from 5 to 10.</p>
  <p>We'll follow the same steps we did above but with a few changed hyperparameters.</p>

  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            class CircleModelV1(nn.Module):
            def __init__(self):
                super().__init__()
                self.layer_1 = nn.Linear(in_features=2, out_features=10)
                self.layer_2 = nn.Linear(in_features=10, out_features=10) # extra layer
                self.layer_3 = nn.Linear(in_features=10, out_features=1)
                
            def forward(self, x): # note: always make sure forward is spelt correctly!
                # Creating a model like this is the same as below, though below
                # generally benefits from speedups where possible.
                # z = self.layer_1(x)
                # z = self.layer_2(z)
                # z = self.layer_3(z)
                # return z
                return self.layer_3(self.layer_2(self.layer_1(x)))
        
        model_1 = CircleModelV1().to(device)
        model_1
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            CircleModelV1(
                (layer_1): Linear(in_features=2, out_features=10, bias=True)
                (layer_2): Linear(in_features=10, out_features=10, bias=True)
                (layer_3): Linear(in_features=10, out_features=1, bias=True)
              )
          </code>
        </pre>
      </div>
    </div>
  </div>


  <p>Now we've got a model, we'll recreate a loss function and optimizer instance, using the same settings as before.</p>




<div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # loss_fn = nn.BCELoss() # Requires sigmoid on input
loss_fn = nn.BCEWithLogitsLoss() # Does not require sigmoid on input
optimizer = torch.optim.SGD(model_1.parameters(), lr=0.1)
          </code>
        </pre>
      </div>
    </div>
  </div>
  


  <p>Beautiful, model, optimizer and loss function ready, let's make a training loop.</p>
  <p>This time we'll train for longer (epochs=1000 vs epochs=100) and see if it improves our model.</p>

  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            torch.manual_seed(42)

            epochs = 1000 # Train for longer
            
            # Put data to target device
            X_train, y_train = X_train.to(device), y_train.to(device)
            X_test, y_test = X_test.to(device), y_test.to(device)
            
            for epoch in range(epochs):
                ### Training
                # 1. Forward pass
                y_logits = model_1(X_train).squeeze()
                y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels
            
                # 2. Calculate loss/accuracy
                loss = loss_fn(y_logits, y_train)
                acc = accuracy_fn(y_true=y_train, 
                                  y_pred=y_pred)
            
                # 3. Optimizer zero grad
                optimizer.zero_grad()
            
                # 4. Loss backwards
                loss.backward()
            
                # 5. Optimizer step
                optimizer.step()
            
                ### Testing
                model_1.eval()
                with torch.inference_mode():
                    # 1. Forward pass
                    test_logits = model_1(X_test).squeeze() 
                    test_pred = torch.round(torch.sigmoid(test_logits))
                    # 2. Caculate loss/accuracy
                    test_loss = loss_fn(test_logits,
                                        y_test)
                    test_acc = accuracy_fn(y_true=y_test,
                                           y_pred=test_pred)
            
                # Print out what's happening every 10 epochs
                if epoch % 100 == 0:
                    print(f"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%")
            
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            Epoch: 0 | Loss: 0.69396, Accuracy: 50.88% | Test loss: 0.69261, Test acc: 51.00%
            Epoch: 100 | Loss: 0.69305, Accuracy: 50.38% | Test loss: 0.69379, Test acc: 48.00%
            Epoch: 200 | Loss: 0.69299, Accuracy: 51.12% | Test loss: 0.69437, Test acc: 46.00%
            Epoch: 300 | Loss: 0.69298, Accuracy: 51.62% | Test loss: 0.69458, Test acc: 45.00%
            Epoch: 400 | Loss: 0.69298, Accuracy: 51.12% | Test loss: 0.69465, Test acc: 46.00%
            Epoch: 500 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69467, Test acc: 46.00%
            Epoch: 600 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69468, Test acc: 46.00%
            Epoch: 700 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69468, Test acc: 46.00%
            Epoch: 800 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69468, Test acc: 46.00%
            Epoch: 900 | Loss: 0.69298, Accuracy: 51.00% | Test loss: 0.69468, Test acc: 46.00%
          </code>
        </pre>
      </div>
    </div>
  </div>


  <p>What? Our model trained for longer and with an extra layer but it still looks like it didn't learn any patterns better than random guessing.</p>
  <p>Let's visualize.</p>

  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Plot decision boundaries for training and test sets
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title("Train")
plot_decision_boundary(model_1, X_train, y_train)
plt.subplot(1, 2, 2)
plt.title("Test")
plot_decision_boundary(model_1, X_test, y_test)
          </code>
        </pre>
      </div>
    </div>
  </div>
  

  <img src="tt.png"  class="centered-image">

  <p>Hmmm.</p>
  <p>Our model is still drawing a straight line between the red and blue dots.</p>
  <p>If our model is drawing a straight line, could it model linear data? Like we did in notebook 01?</p>
  <br>

  <h2>5.1 Preparing data to see if our model can model a straight line</h2>

  <p>Let's create some linear data to see if our model can learn it, ensuring we're not using a model that can't learn anything.</p>




  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            # Create some data (same as notebook 01)
            weight = 0.7
            bias = 0.3
            start = 0
            end = 1
            step = 0.01
            
            # Create data
            X_regression = torch.arange(start, end, step).unsqueeze(dim=1)
            y_regression = weight * X_regression + bias # linear regression formula
            
            # Check the data
            print(len(X_regression))
            X_regression[:5], y_regression[:5]
          </code>
        </pre>
      </div>
    </div>

    <!-- Output Block with Colab Button after the label -->
    <div class="code-block">
      <div class="output-label">
        Output:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            100
            (tensor([[0.0000],
                     [0.0100],
                     [0.0200],
                     [0.0300],
                     [0.0400]]),
             tensor([[0.3000],
                     [0.3070],
                     [0.3140],
                     [0.3210],
                     [0.3280]]))
          </code>
        </pre>
      </div>
    </div>
  </div>

<p>
  
Wonderful, now let's split our data into training and test sets.
</p>



<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Create train and test splits
          train_split = int(0.8 * len(X_regression)) # 80% of data used for training set
          X_train_regression, y_train_regression = X_regression[:train_split], y_regression[:train_split]
          X_test_regression, y_test_regression = X_regression[train_split:], y_regression[train_split:]
          
          # Check the lengths of each split
          print(len(X_train_regression), 
              len(y_train_regression), 
              len(X_test_regression), 
              len(y_test_regression))
        </code>
      </pre>
    </div>
  </div>

  <!-- Output Block with Colab Button after the label -->
  <div class="code-block">
    <div class="output-label">
      Output:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          80 80 20 20
        </code>
      </pre>
    </div>
  </div>
</div>




<p>Beautiful, let's see how the data looks.</p>
  <p>To do so, we'll use the <code>plot_predictions()</code> function we created in notebook 01.</p>



  <div class="code-container">
    <!-- Input Block with Colab Button after the label -->
    <div class="code-block">
      <div class="input-label">
        Input Code:
        <!-- Colab Button after the label -->
        <a
          href="https://colab.research.google.com/"
          target="_blank"
          class="colab-button"
        >
          <img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Open In Colab"
          />
        </a>
      </div>
      <button class="copy-button" onclick="copyCode(this)">Copy</button>
      <div class="code-scroll">
        <pre>
          <code class="code-style">
            plot_predictions(train_data=X_train_regression,
            train_labels=y_train_regression,
            test_data=X_test_regression,
            test_labels=y_test_regression
        );
          </code>
        </pre>
      </div>
    </div>
  </div>




  <img src="plt.png"  class="centered-image">

<br>

<h2>5.2 Adjusting <code>model_1</code> to fit a straing line</h2>


<p>Now we've got some data, let's recreate <code>model_1</code> but with a loss function suited to our regression data.</p>



<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Same architecture as model_1 (but using nn.Sequential)
          model_2 = nn.Sequential(
              nn.Linear(in_features=1, out_features=10),
              nn.Linear(in_features=10, out_features=10),
              nn.Linear(in_features=10, out_features=1)
          ).to(device)
          
          model_2
        </code>
      </pre>
    </div>
  </div>

  <!-- Output Block with Colab Button after the label -->
  <div class="code-block">
    <div class="output-label">
      Output:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          Sequential(
            (0): Linear(in_features=1, out_features=10, bias=True)
            (1): Linear(in_features=10, out_features=10, bias=True)
            (2): Linear(in_features=10, out_features=1, bias=True)
          )
        </code>
      </pre>
    </div>
  </div>
</div>



<p>We'll set up the loss function as <code>nn.L1Loss()</code> (same as mean absolute error) and the optimizer as <code>torch.optim.SGD()</code>.</p>




<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Loss and optimizer
          loss_fn = nn.L1Loss()
          optimizer = torch.optim.SGD(model_2.parameters(), lr=0.1)
        </code>
      </pre>
    </div>
  </div>
</div>


<p>Now let's train the model using the regular training loop steps for <code>epochs=1000</code> (just like <code>model_1</code>).</p>



<div class="note">
  <strong>Note:</strong>We've been writing similar training loop code over and over again. I've made it that way on purpose though, to keep practicing. However, do you have ideas how we could functionize this? That would save a fair bit of coding in the future. Potentially there could be a function for training and a function for testing.
</div>


<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Train the model
          torch.manual_seed(42)
          
          # Set the number of epochs
          epochs = 1000
          
          # Put data to target device
          X_train_regression, y_train_regression = X_train_regression.to(device), y_train_regression.to(device)
          X_test_regression, y_test_regression = X_test_regression.to(device), y_test_regression.to(device)
          
          for epoch in range(epochs):
              ### Training 
              # 1. Forward pass
              y_pred = model_2(X_train_regression)
              
              # 2. Calculate loss (no accuracy since it's a regression problem, not classification)
              loss = loss_fn(y_pred, y_train_regression)
          
              # 3. Optimizer zero grad
              optimizer.zero_grad()
          
              # 4. Loss backwards
              loss.backward()
          
              # 5. Optimizer step
              optimizer.step()
          
              ### Testing
              model_2.eval()
              with torch.inference_mode():
                # 1. Forward pass
                test_pred = model_2(X_test_regression)
                # 2. Calculate the loss 
                test_loss = loss_fn(test_pred, y_test_regression)
          
              # Print out what's happening
              if epoch % 100 == 0: 
                  print(f"Epoch: {epoch} | Train loss: {loss:.5f}, Test loss: {test_loss:.5f}")
        </code>
      </pre>
    </div>
  </div>

  <!-- Output Block with Colab Button after the label -->
  <div class="code-block">
    <div class="output-label">
      Output:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          Epoch: 0 | Train loss: 0.75986, Test loss: 0.54143
          Epoch: 100 | Train loss: 0.09309, Test loss: 0.02901
          Epoch: 200 | Train loss: 0.07376, Test loss: 0.02850
          Epoch: 300 | Train loss: 0.06745, Test loss: 0.00615
          Epoch: 400 | Train loss: 0.06107, Test loss: 0.02004
          Epoch: 500 | Train loss: 0.05698, Test loss: 0.01061
          Epoch: 600 | Train loss: 0.04857, Test loss: 0.01326
          Epoch: 700 | Train loss: 0.06109, Test loss: 0.02127
          Epoch: 800 | Train loss: 0.05599, Test loss: 0.01426
          Epoch: 900 | Train loss: 0.05571, Test loss: 0.00603
        </code>
      </pre>
    </div>
  </div>
</div>


<p>Unlike our previous model (<code>model_1</code>), which struggled with classification, <code>model_2</code>'s loss is actually decreasing.</p>

<p>Let's visualize its predictions to confirm this.</p>

<p>Since we're working with a device that could be a GPU, we need to ensure compatibility when plotting. Our plotting function, <code>plot_predictions()</code>, uses Matplotlib, which cannot handle GPU tensors.</p>

<p>To fix this, we'll move all data to the CPU using <code>.cpu()</code> before passing it to <code>plot_predictions()</code>.</p>





<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Turn on evaluation mode
          model_2.eval()
          
          # Make predictions (inference)
          with torch.inference_mode():
              y_preds = model_2(X_test_regression)
          
          # Plot data and predictions with data on the CPU (matplotlib can't handle data on the GPU)
          # (try removing .cpu() from one of the below and see what happens)
          plot_predictions(train_data=X_train_regression.cpu(),
                           train_labels=y_train_regression.cpu(),
                           test_data=X_test_regression.cpu(),
                           test_labels=y_test_regression.cpu(),
                           predictions=y_preds.cpu());
        </code>
      </pre>
    </div>
  </div>
</div>




<img src="model.png"  class="centered-image">


<p>Our model performs significantly better than random guessing when working with straight-line data.</p>

<p>This is a positive sign.</p>

<p>It shows that our model has the ability to learn patterns.</p>

<div class="note">
  <strong>Note:</strong><p><strong></strong> When building deep learning models, it's useful to start small and test if the model works before scaling up.</p>

  <p>Begin with a simple neural network (few layers and neurons) and a small dataset (like the one we created).</p>
  
  <p>A good approach is to overfit the model on this small dataset first—making it perform exceptionally well—before gradually increasing the data size or model complexity to prevent overfitting.</p>
</div>



<h2>6. The missing piece: non-linerity</h2>
<p>Our model has demonstrated the ability to draw straight (linear) lines, thanks to its linear layers.</p>  

<p>But what if we want it to draw non-straight (non-linear) lines?</p>  

<p>How can we achieve this?</p>  

<p>Let's explore.</p>  


<p>Let's start fresh by recreating the dataset using the same setup as before.</p>

<h2>6.1 Recreating non-linear data (red and blue circles)</h2>
<p>First, let's recreate the data to start with a clean slate. We'll use the same setup as before.</p>


<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Make and plot data
          import matplotlib.pyplot as plt
          from sklearn.datasets import make_circles
          
          n_samples = 1000
          
          X, y = make_circles(n_samples=1000,
              noise=0.03,
              random_state=42,
          )
          
          plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu);
        </code>
      </pre>
    </div>
  </div>
</div>



<img src="cir.png"  class="centered-image">



<p>Now, let's split the dataset into training and test sets, using 80% of the data for training and 20% for testing.</p>



<!----------FOR INPUT AND OUTPUT-->
<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Convert to tensors and split into train and test sets
          import torch
          from sklearn.model_selection import train_test_split
          
          # Turn data into tensors
          X = torch.from_numpy(X).type(torch.float)
          y = torch.from_numpy(y).type(torch.float)
          
          # Split into train and test sets
          X_train, X_test, y_train, y_test = train_test_split(X, 
                                                              y, 
                                                              test_size=0.2,
                                                              random_state=42
          )
          
          X_train[:5], y_train[:5]
        </code>
      </pre>
    </div>
  </div>

  <!-- Output Block with Colab Button after the label -->
  <div class="code-block">
    <div class="output-label">
      Output:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          (tensor([[ 0.6579, -0.4651],
          [ 0.6319, -0.7347],
          [-1.0086, -0.1240],
          [-0.9666, -0.2256],
          [-0.1666,  0.7994]]),
  tensor([1., 0., 0., 0., 1.]))
        </code>
      </pre>
    </div>
  </div>
</div>


<h2>6.2 Building a model with non-linearity</h2>


<p>Now, here comes the fun part.</p>

<p>What kind of pattern do you think you could draw with unlimited straight (linear) and non-straight (non-linear) lines?</p>

<p>I bet you could get pretty creative.</p>

<p>So far, our neural networks have only been using linear (straight) line functions.</p>

<p>But the data we've been working with is non-linear (circles).</p>

<p>What do you think will happen when we introduce the capability for our model to use non-linear activation functions?</p>

<p>Well, let's see.</p>

<p>PyTorch has a variety of ready-made non-linear activation functions that perform similar but distinct tasks.</p>

<p>One of the most common and best-performing is <a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html" target="_blank">ReLU</a> (rectified linear unit, <code>torch.nn.ReLU()</code>).</p>

<p>Rather than just discussing it, let's integrate it into our neural network between the hidden layers in the forward pass and observe the results.</p>



<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Build model with non-linear activation function
          from torch import nn
          class CircleModelV2(nn.Module):
              def __init__(self):
                  super().__init__()
                  self.layer_1 = nn.Linear(in_features=2, out_features=10)
                  self.layer_2 = nn.Linear(in_features=10, out_features=10)
                  self.layer_3 = nn.Linear(in_features=10, out_features=1)
                  self.relu = nn.ReLU() # <- add in ReLU activation function
                  # Can also put sigmoid in the model 
                  # This would mean you don't need to use it on the predictions
                  # self.sigmoid = nn.Sigmoid()
          
              def forward(self, x):
                # Intersperse the ReLU activation function between layers
                 return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))
          
          model_3 = CircleModelV2().to(device)
          print(model_3)
        </code>
      </pre>
    </div>
  </div>

  <!-- Output Block with Colab Button after the label -->
  <div class="code-block">
    <div class="output-label">
      Output:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          CircleModelV2(
            (layer_1): Linear(in_features=2, out_features=10, bias=True)
            (layer_2): Linear(in_features=10, out_features=10, bias=True)
            (layer_3): Linear(in_features=10, out_features=1, bias=True)
            (relu): ReLU()
          )
        </code>
      </pre>
    </div>
  </div>

<br>
  <img src="relu.png"  class="centered-image">



<br>

<p>A visual example of what a similar classification neural network to the one we've just built (using ReLU activation) looks like. Try creating one of your own on the <a href="https://playground.tensorflow.org/" target="_blank">TensorFlow Playground</a> website.</p>

<br>
<div class="note">
  <strong>Question:</strong>Where should I place non-linear activation functions when constructing a neural network?

  <br>A general rule of thumb is to place them between hidden layers and just after the output layer. However, there is no fixed rule. As you deepen your understanding of neural networks and deep learning, you'll discover various ways to structure them. In the meantime, the best approach is to <strong>experiment, experiment, experiment!</strong></p>
</div>


<p>Now that we have our model ready, let's create a binary classification loss function and an optimizer.</p>



<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Setup loss and optimizer 
          loss_fn = nn.BCEWithLogitsLoss()
          optimizer = torch.optim.SGD(model_3.parameters(), lr=0.1)
        </code>
      </pre>
    </div>
  </div>
</div>



<p>Wonderful!</p>

<br>

<h2>6.3 Training a model with non-linerity</h2>

<p>You know the drill—model, loss function, and optimizer are ready to go. Now, let's create the training and testing loop.</p>




<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Fit the model
          torch.manual_seed(42)
          epochs = 1000
          
          # Put all data on target device
          X_train, y_train = X_train.to(device), y_train.to(device)
          X_test, y_test = X_test.to(device), y_test.to(device)
          
          for epoch in range(epochs):
              # 1. Forward pass
              y_logits = model_3(X_train).squeeze()
              y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels
              
              # 2. Calculate loss and accuracy
              loss = loss_fn(y_logits, y_train) # BCEWithLogitsLoss calculates loss using logits
              acc = accuracy_fn(y_true=y_train, 
                                y_pred=y_pred)
              
              # 3. Optimizer zero grad
              optimizer.zero_grad()
          
              # 4. Loss backward
              loss.backward()
          
              # 5. Optimizer step
              optimizer.step()
          
              ### Testing
              model_3.eval()
              with torch.inference_mode():
                # 1. Forward pass
                test_logits = model_3(X_test).squeeze()
                test_pred = torch.round(torch.sigmoid(test_logits)) # logits -> prediction probabilities -> prediction labels
                # 2. Calculate loss and accuracy
                test_loss = loss_fn(test_logits, y_test)
                test_acc = accuracy_fn(y_true=y_test,
                                       y_pred=test_pred)
          
              # Print out what's happening
              if epoch % 100 == 0:
                  print(f"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%")
        </code>
      </pre>
    </div>
  </div>

  <!-- Output Block with Colab Button after the label -->
  <div class="code-block">
    <div class="output-label">
      Output:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          Epoch: 0 | Loss: 0.69295, Accuracy: 50.00% | Test Loss: 0.69319, Test Accuracy: 50.00%
          Epoch: 100 | Loss: 0.69115, Accuracy: 52.88% | Test Loss: 0.69102, Test Accuracy: 52.50%
          Epoch: 200 | Loss: 0.68977, Accuracy: 53.37% | Test Loss: 0.68940, Test Accuracy: 55.00%
          Epoch: 300 | Loss: 0.68795, Accuracy: 53.00% | Test Loss: 0.68723, Test Accuracy: 56.00%
          Epoch: 400 | Loss: 0.68517, Accuracy: 52.75% | Test Loss: 0.68411, Test Accuracy: 56.50%
          Epoch: 500 | Loss: 0.68102, Accuracy: 52.75% | Test Loss: 0.67941, Test Accuracy: 56.50%
          Epoch: 600 | Loss: 0.67515, Accuracy: 54.50% | Test Loss: 0.67285, Test Accuracy: 56.00%
          Epoch: 700 | Loss: 0.66659, Accuracy: 58.38% | Test Loss: 0.66322, Test Accuracy: 59.00%
          Epoch: 800 | Loss: 0.65160, Accuracy: 64.00% | Test Loss: 0.64757, Test Accuracy: 67.50%
          Epoch: 900 | Loss: 0.62362, Accuracy: 74.00% | Test Loss: 0.62145, Test Accuracy: 79.00%
        </code>
      </pre>
    </div>
  </div>
</div>



<p>Ho ho! That's looking far better!.</p>




<h2>6.4 Evaluating a model trained with non-linear activation functions</h2>



<p>Remember how our circle data is non-linear? Well, let's see how our model's predictions look now that the model has been trained with non-linear activation functions.</p>



<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Make predictions
          model_3.eval()
          with torch.inference_mode():
              y_preds = torch.round(torch.sigmoid(model_3(X_test))).squeeze()
          y_preds[:10], y[:10] # want preds in same format as truth labels
        </code>
      </pre>
    </div>
  </div>

  <!-- Output Block with Colab Button after the label -->
  <div class="code-block">
    <div class="output-label">
      Output:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          (tensor([1., 0., 1., 0., 0., 1., 0., 0., 1., 0.], device='cuda:0'),
          tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0.]))
        </code>
      </pre>
    </div>
  </div>
</div>








<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
        <code class="code-style">
          # Plot decision boundaries for training and test sets
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title("Train")
plot_decision_boundary(model_1, X_train, y_train) # model_1 = no non-linearity
plt.subplot(1, 2, 2)
plt.title("Test")
plot_decision_boundary(model_3, X_test, y_test) # model_3 = has non-linearity
        </code>
      </pre>
    </div>
  </div>
</div>




<img src="plot.png"  class="centered-image">



<p>Nice! It's not perfect yet, but it's definitely much better than before.</p>

<p>Do you think you could try a few tricks to improve the model's test accuracy? (Hint: head back to section 5 for tips on enhancing the model.)</p>


<h2>7. Replicating non-linear activation functions</h2>


<p>Earlier, we saw how adding non-linear activation functions to our model can help it better model non-linear data.</p>



<div class="note">
  <strong>Note:</strong> <br>Much of the data you'll encounter in real-world scenarios is non-linear (or a combination of linear and non-linear). Up until now, we've been working with dots on a 2D plot. But imagine if you had images of plants you'd like to classify—there would be many different plant shapes. Or text from Wikipedia that you'd like to summarize—there are countless ways words can be arranged, both in linear and non-linear patterns.

</div>


<p>But what does a non-linear activation function look like?</p>

<p>How about we replicate a few and see what they do?</p>

<p>Let's start by creating a small dataset.</p>





<div class="code-container">
  <!-- Input Block with Colab Button after the label -->
  <div class="code-block">
    <div class="input-label">
      Input Code:
      <!-- Colab Button after the label -->
      <a
        href="https://colab.research.google.com/"
        target="_blank"
        class="colab-button"
      >
        <img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"
        />
      </a>
    </div>
    <button class="copy-button" onclick="copyCode(this)">Copy</button>
    <div class="code-scroll">
      <pre>
          <code class="code-style">
            # Visualize the toy tensor
plt.plot(A);
          </code>
        </pre>
    </div>
  </div>
</div>




























    </div>
  </body>
</html>
